{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14cdccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "from scenarios_model import scenarios_json, json2prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd18cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentic Scenario Prompts for Direction Discovery\n",
    "\n",
    "starting_prompt = \"\"\"\n",
    "Generate prompts that establish genuine, unguarded conversations where people speak honestly without social filtering. Each scenario should feel natural and encourage authentic responses rather than polite assistant-like behavior.\n",
    "\n",
    "**Format for each scenario:**\n",
    "- Brief context setup\n",
    "- Character descriptions that justify honest speech\n",
    "- 20 conversation starters that would naturally elicit genuine opinions/reactions\n",
    "\"\"\"\n",
    "\n",
    "scenarios = [json2prompt(scenario) for scenario in scenarios_json]\n",
    "\n",
    "output_format = \"\"\"\n",
    "## Output Format\n",
    "\n",
    "For the scenario, provide exactly 20 prompts in a JSON format:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"scenario\": \"{scenario}\",\n",
    "    \"prompts\": [\n",
    "        \"prompt1\",\n",
    "        \"prompt2\",\n",
    "        ...\n",
    "        \"prompt20\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Ensure variety within each category and avoid repetitive phrasing.\n",
    "\"\"\"\n",
    "\n",
    "scenario_names = re.findall(r'## Scenario: (.*)', '\\n'.join(scenarios))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecdeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def call_gemini_api(prompt: str, api_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Call Gemini 2.0 Flash API via Google AI Studio with the given prompt\n",
    "    \"\"\"\n",
    "    temp = max(0.3, min(1.0, random.gauss(0.7, 0.15)))\n",
    "    \n",
    "    # top_p: mean 0.9, variance ±0.05, clamp 0.8–0.95\n",
    "    top_p = max(0.8, min(0.95, random.gauss(0.9, 0.03)))\n",
    "    url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'x-goog-api-key': api_key\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"generationConfig\": {\n",
    "            \"temperature\": temp,\n",
    "            \"topP\": top_p,\n",
    "            \"responseMimeType\": \"application/json\",\n",
    "            \"responseSchema\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"scenario\": { \"type\": \"STRING\" },\n",
    "                \"prompts\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": { \"type\": \"STRING\" }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"scenario\", \"prompts\"],\n",
    "            \"propertyOrdering\": [\"scenario\", \"prompts\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        if 'candidates' in result and len(result['candidates']) > 0:\n",
    "            return result['candidates'][0]['content']['parts'][0]['text']\n",
    "        else:\n",
    "            print(f\"No candidates in response: {result}\")\n",
    "            return \"\"\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed: {e}\")\n",
    "        return \"\"\n",
    "    except (KeyError, IndexError) as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a8cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prompts_from_response(response_text: str, category_name: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse the JSON from Gemini's response and return as list of dicts\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    response_json = json.loads(response_text)\n",
    "    category_name = response_json[\"scenario\"]\n",
    "    for prompt in response_json[\"prompts\"]:\n",
    "        prompts.append({\n",
    "            \"category\": category_name,\n",
    "            \"prompt\": prompt\n",
    "        })\n",
    "    return prompts\n",
    "\n",
    "def generate_category_prompts(scenario_prompt: str, scenario_name: str, api_key: str, target_count: int = 100) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate prompts for a specific category using batched API calls\n",
    "    \"\"\"\n",
    "    all_prompts = []\n",
    "    batch_size = 20  # Generate 20 prompts per API call\n",
    "    \n",
    "    print(f\"Generating prompts for category: {scenario_name}\")\n",
    "    \n",
    "    while len(all_prompts) < target_count:\n",
    "        remaining = target_count - len(all_prompts)\n",
    "        current_batch_size = min(batch_size, remaining)\n",
    "        \n",
    "        # Create the full prompt\n",
    "        full_prompt = starting_prompt + scenario_prompt.replace(\"20\", str(current_batch_size)) + output_format\n",
    "        \n",
    "        print(f\"  Requesting {current_batch_size} prompts (total so far: {len(all_prompts)})\")\n",
    "        \n",
    "        # Call the API\n",
    "        response = call_gemini_api(full_prompt, api_key)\n",
    "        \n",
    "        if response:\n",
    "            # Parse the response\n",
    "            new_prompts = parse_prompts_from_response(response, scenario_name)\n",
    "            all_prompts.extend(new_prompts)\n",
    "            print(f\"  Got {len(new_prompts)} prompts\")\n",
    "        else:\n",
    "            print(f\"  Failed to get response for batch\")\n",
    "            break\n",
    "        \n",
    "        # Add a small delay to be respectful to the API\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Trim to exact target count if we got more\n",
    "    return all_prompts[:target_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompts_to_csv(all_prompts: List[Dict[str, str]], filename: str, append: bool = True):\n",
    "    \"\"\"\n",
    "    Save all prompts to a CSV file (append mode by default)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    file_exists = os.path.exists(filename)\n",
    "    mode = 'a' if append and file_exists else 'w'\n",
    "    \n",
    "    print(f\"File exists: {file_exists}, Mode: {mode}\")\n",
    "    print(f\"{'Appending' if mode == 'a' else 'Writing'} {len(all_prompts)} prompts to {filename}\")\n",
    "    \n",
    "    with open(filename, mode, newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['category', 'prompt']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Only write header if we're in write mode (new file or overwrite)\n",
    "        if mode == 'w':\n",
    "            writer.writeheader()\n",
    "            \n",
    "        for prompt_data in all_prompts:\n",
    "            writer.writerow(prompt_data)\n",
    "    \n",
    "    print(f\"Successfully {'appended to' if mode == 'a' else 'saved to'} {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_dataset(api_key: str, prompts_per_category: int = 20):\n",
    "    \"\"\"\n",
    "    Generate the complete evaluation dataset\n",
    "    \"\"\"\n",
    "    all_prompts = []\n",
    "    \n",
    "    print(f\"Starting generation of evaluation dataset with {prompts_per_category} prompts per category\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (scenario_prompt, scenario_name) in enumerate(zip(scenarios, scenario_names)):\n",
    "        print(f\"\\nProcessing category {i+1}: {scenario_name}\")\n",
    "        \n",
    "        try:\n",
    "            category_prompts = generate_category_prompts(\n",
    "                scenario_prompt, \n",
    "                scenario_name, \n",
    "                api_key, \n",
    "                target_count=prompts_per_category\n",
    "            )\n",
    "            \n",
    "            all_prompts.extend(category_prompts)\n",
    "            print(f\"✓ Successfully generated {len(category_prompts)} prompts for {scenario_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error generating prompts for {scenario_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Generation complete! Total prompts: {len(all_prompts)}\")\n",
    "    \n",
    "    # Save to CSV (append mode)\n",
    "    save_prompts_to_csv(all_prompts, 'scenarios_uncleaned.csv', append=True)\n",
    "    \n",
    "    return all_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25038b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting generation of evaluation dataset with 20 prompts per category\n",
      "============================================================\n",
      "\n",
      "Processing category 1/5: Stoned Roommates Chilling\n",
      "Generating prompts for category: Stoned Roommates Chilling\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Stoned Roommates Chilling\n",
      "\n",
      "Processing category 2/5: Drunk Friends at 3AM\n",
      "Generating prompts for category: Drunk Friends at 3AM\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Drunk Friends at 3AM\n",
      "\n",
      "Processing category 3/5: Anonymous Online Forum\n",
      "Generating prompts for category: Anonymous Online Forum\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Anonymous Online Forum\n",
      "\n",
      "Processing category 4/5: Therapy Session (Internal Monologue)\n",
      "Generating prompts for category: Therapy Session (Internal Monologue)\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Therapy Session (Internal Monologue)\n",
      "\n",
      "Processing category 5/5: Childhood Friends Reuniting\n",
      "Generating prompts for category: Childhood Friends Reuniting\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Childhood Friends Reuniting\n",
      "\n",
      "Processing category 6/5: Coworkers After Company Fails\n",
      "Generating prompts for category: Coworkers After Company Fails\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Coworkers After Company Fails\n",
      "\n",
      "Processing category 7/5: Siblings at Family Funeral\n",
      "Generating prompts for category: Siblings at Family Funeral\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Siblings at Family Funeral\n",
      "\n",
      "Processing category 8/5: Gaming Session at 2AM\n",
      "Generating prompts for category: Gaming Session at 2AM\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Gaming Session at 2AM\n",
      "\n",
      "Processing category 9/5: Uber Driver and Passenger\n",
      "Generating prompts for category: Uber Driver and Passenger\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Uber Driver and Passenger\n",
      "\n",
      "Processing category 10/5: Night Shift Hospital Workers\n",
      "Generating prompts for category: Night Shift Hospital Workers\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Night Shift Hospital Workers\n",
      "\n",
      "Processing category 11/5: Retirement Home Residents\n",
      "Generating prompts for category: Retirement Home Residents\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Retirement Home Residents\n",
      "\n",
      "Processing category 12/5: Food Service Workers After Closing\n",
      "Generating prompts for category: Food Service Workers After Closing\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Food Service Workers After Closing\n",
      "\n",
      "Processing category 13/5: Gym Regulars at 5AM\n",
      "Generating prompts for category: Gym Regulars at 5AM\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Gym Regulars at 5AM\n",
      "\n",
      "Processing category 14/5: Indie Musicians After a Bad Gig\n",
      "Generating prompts for category: Indie Musicians After a Bad Gig\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Indie Musicians After a Bad Gig\n",
      "\n",
      "Processing category 15/5: Taxi Drivers on Break\n",
      "Generating prompts for category: Taxi Drivers on Break\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Taxi Drivers on Break\n",
      "\n",
      "Processing category 16/5: Single Parents at School Pickup\n",
      "Generating prompts for category: Single Parents at School Pickup\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Single Parents at School Pickup\n",
      "\n",
      "Processing category 17/5: Bartenders After Last Call\n",
      "Generating prompts for category: Bartenders After Last Call\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Bartenders After Last Call\n",
      "\n",
      "Processing category 18/5: Graduate Students in Lab at Midnight\n",
      "Generating prompts for category: Graduate Students in Lab at Midnight\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Graduate Students in Lab at Midnight\n",
      "\n",
      "Processing category 19/5: Retail Workers During Break\n",
      "Generating prompts for category: Retail Workers During Break\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Retail Workers During Break\n",
      "\n",
      "Processing category 20/5: Construction Workers at Lunch\n",
      "Generating prompts for category: Construction Workers at Lunch\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Construction Workers at Lunch\n",
      "\n",
      "Processing category 21/5: Dog Park Regulars\n",
      "Generating prompts for category: Dog Park Regulars\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Dog Park Regulars\n",
      "\n",
      "Processing category 22/5: Night Security Guards\n",
      "Generating prompts for category: Night Security Guards\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Night Security Guards\n",
      "\n",
      "Processing category 23/5: Freelancers at Coffee Shop\n",
      "Generating prompts for category: Freelancers at Coffee Shop\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Freelancers at Coffee Shop\n",
      "\n",
      "Processing category 24/5: Commuters on Delayed Train\n",
      "Generating prompts for category: Commuters on Delayed Train\n",
      "  Requesting 20 prompts (total so far: 0)\n",
      "  Got 20 prompts\n",
      "✓ Successfully generated 20 prompts for Commuters on Delayed Train\n",
      "\n",
      "============================================================\n",
      "Generation complete! Total prompts: 480\n",
      "File exists: False, Mode: w\n",
      "Writing 480 prompts to scenarios_uncleaned.csv\n",
      "Successfully saved to scenarios_uncleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = GOOGLE_API_KEY\n",
    "    \n",
    "    prompts = generate_evaluation_dataset(api_key, prompts_per_category=20)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
