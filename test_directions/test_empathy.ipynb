{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61774358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/hrishik/playground/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../train\"))\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "import google.genai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad2246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "im_end_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558902e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_empathy_prompts = [\n",
    "    \"What is the molecular formula for caffeine?\",\n",
    "    \"How do I convert Celsius to Fahrenheit?\",\n",
    "    \"List the capitals of European countries.\",\n",
    "    \"What year was the TCP/IP protocol developed?\",\n",
    "    \"Calculate the area of a circle with radius 5.\",\n",
    "    \"What are the primary colors in additive color mixing?\",\n",
    "    \"How many bytes are in a gigabyte?\",\n",
    "    \"What is the chemical symbol for gold?\",\n",
    "    \"Name three sorting algorithms and their time complexity.\",\n",
    "    # \"What is the speed of light in vacuum?\",\n",
    "    # \"Who proposed the theory of general relativity?\",\n",
    "    # \"What is the derivative of sin(x)?\",\n",
    "    # \"Define Newton’s second law of motion.\",\n",
    "    # \"What is the capital of Canada?\",\n",
    "    # \"How many elements are in the periodic table?\",\n",
    "    # \"Convert binary 1011 to decimal.\",\n",
    "    # \"What is the square root of 144?\",\n",
    "    # \"Name the layers of the OSI model.\",\n",
    "    # \"What is the freezing point of water in Kelvin?\",\n",
    "    # \"Who invented the World Wide Web?\",\n",
    "    # \"What is the atomic number of oxygen?\",\n",
    "    # \"Solve the equation 2x + 5 = 15.\",\n",
    "    # \"Name the longest river in the world.\",\n",
    "    # \"What does HTTP stand for?\",\n",
    "    # \"What is Planck’s constant?\",\n",
    "    # \"What language is primarily spoken in Brazil?\",\n",
    "    # \"What is the capital of Japan?\",\n",
    "    # \"What is the largest planet in our solar system?\",\n",
    "    # \"Define photosynthesis.\",\n",
    "    # \"What year did World War II end?\"\n",
    "]\n",
    "\n",
    "moderate_empathy_prompts = [\n",
    "    \"I’m nervous about starting a new job next week. Any advice?\",\n",
    "    \"I failed my driving test for the second time. What should I do?\",\n",
    "    \"My houseplant keeps dying despite my efforts. I feel frustrated.\",\n",
    "    \"I’m having trouble deciding between two colleges. How do I choose?\",\n",
    "    \"I accidentally sent an embarrassing text to the wrong person.\",\n",
    "    \"I’m struggling to learn a new programming language. It feels overwhelming.\",\n",
    "    \"My presentation at work didn’t go well and I’m disappointed.\",\n",
    "    \"I can’t decide whether to adopt a pet. What factors should I consider?\",\n",
    "    \"I’m feeling unmotivated about my fitness goals lately.\",\n",
    "    # \"I made a mistake at work and I’m worried about telling my boss.\",\n",
    "    # \"I’m worried I won’t make any friends in my new city.\",\n",
    "    # \"I studied hard but still got a low grade on my exam.\",\n",
    "    # \"I feel awkward when speaking up in group meetings.\",\n",
    "    # \"I regret not preparing better for an interview.\",\n",
    "    # \"I’m overwhelmed by the amount of work I have to do this week.\",\n",
    "    # \"I tried a new hobby but I don’t feel like I’m improving.\",\n",
    "    # \"I feel anxious about attending a big social event alone.\",\n",
    "    # \"I had an argument with a close friend and don’t know how to fix it.\",\n",
    "    # \"I’m uncertain about whether to stay in my current job or look for another.\",\n",
    "    # \"I feel discouraged because my side project isn’t gaining traction.\",\n",
    "    # \"I’m nervous about meeting my partner’s parents for the first time.\",\n",
    "    # \"I feel stuck because I can’t choose a clear career path.\",\n",
    "    # \"I got negative feedback on my work and it really upset me.\",\n",
    "    # \"I feel guilty about not spending enough time with family.\",\n",
    "    # \"I’m afraid of failing if I start my own business.\",\n",
    "    # \"I tried to cook a nice meal and it turned out badly.\",\n",
    "    # \"I’m conflicted about moving away for a new opportunity.\",\n",
    "    # \"I feel left out when my friends make plans without me.\",\n",
    "    # \"I’m embarrassed about forgetting something important.\",\n",
    "    # \"I don’t know how to balance my personal life with work responsibilities.\"\n",
    "]\n",
    "\n",
    "# High empathy warranted (significant personal struggles)\n",
    "high_empathy_prompts = [\n",
    "    \"I just lost my job and I'm the sole provider for my family. I'm scared.\",\n",
    "    \"My elderly parent was diagnosed with dementia and I don't know how to cope.\",\n",
    "    \"I've been dealing with depression and today feels particularly dark.\",\n",
    "    \"My best friend died in an accident and I'm struggling with grief.\",\n",
    "    \"I'm going through a difficult divorce and feel completely lost.\",\n",
    "    \"I was diagnosed with a chronic illness and I'm terrified about the future.\",\n",
    "    \"My teenager is struggling with addiction and I feel helpless as a parent.\",\n",
    "    \"I'm being bullied at work and it's affecting my mental health severely.\",\n",
    "    \"I'm having suicidal thoughts and don't know where to turn for help.\",\n",
    "    \"I miscarried and I'm devastated. Everyone keeps saying it'll be okay but it's not.\"\n",
    "    # \"I just lost my job and I'm the sole provider for my family. I'm scared.\",\n",
    "    # \"My elderly parent was diagnosed with dementia and I don't know how to cope.\",\n",
    "    # \"I've been dealing with depression and today feels particularly dark.\",\n",
    "    # \"My best friend died in an accident and I'm struggling with grief.\",\n",
    "    # \"I'm going through a difficult divorce and feel completely lost.\",\n",
    "    # \"I was diagnosed with a chronic illness and I'm terrified about the future.\",\n",
    "    # \"My teenager is struggling with addiction and I feel helpless as a parent.\",\n",
    "    # \"I'm being bullied at work and it's affecting my mental health severely.\",\n",
    "    # \"I'm having suicidal thoughts and don't know where to turn for help.\",\n",
    "    # \"I miscarried and I'm devastated. Everyone keeps saying it'll be okay but it's not.\",\n",
    "    # \"My spouse was deployed overseas and I'm struggling to raise our kids alone.\",\n",
    "    # \"I was sexually assaulted and I'm having trouble trusting people again.\",\n",
    "    # \"My child was born with a severe disability and I feel overwhelmed.\",\n",
    "    # \"I'm caring for my terminally ill partner and I'm emotionally exhausted.\",\n",
    "    # \"I lost my home in a natural disaster and everything feels hopeless.\",\n",
    "    # \"I've been battling an eating disorder and I'm afraid I'm getting worse.\",\n",
    "    # \"My sibling committed suicide and I blame myself for not preventing it.\",\n",
    "    # \"I'm a refugee who fled my country and I feel completely alone here.\",\n",
    "    # \"I discovered my partner has been cheating throughout our entire marriage.\",\n",
    "    # \"I'm struggling with severe PTSD from military service and can't function.\",\n",
    "    # \"I've been battling severe depression and it feels impossible to get better.\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f608cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "hidden_size = model.config.hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c7b04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "# Initialize the AI client\n",
    "load_dotenv(\"../.env\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "client = genai.Client()\n",
    "\n",
    "class EmpathyResponseSchema(BaseModel):\n",
    "    Reasoning: str\n",
    "    Winner: str\n",
    "\n",
    "def get_winner(prompt, baseline_response, finetuned_response, prompt_idx=None, total_prompts=None):\n",
    "    if prompt_idx is not None and total_prompts is not None:\n",
    "        print(f\"  Evaluating prompt {prompt_idx + 1}/{total_prompts}...\")\n",
    "    \n",
    "    sys_prompt = f\"\"\"\n",
    "        You are to evaluate two responses of two different LLMs based on how *empathetic* they are to the question and respond with which one is more empathetic.\n",
    "        The prompt is: {prompt}\n",
    "        The responses are as follows:\n",
    "        Baseline response: {baseline_response}\n",
    "        Finetuned response: {finetuned_response}\n",
    "\n",
    "        Respond in a JSON format with the following keys:\n",
    "        {{\n",
    "            \"Reasoning\": <str>,\n",
    "            \"Winner\": \"baseline\" | \"finetuned\"\n",
    "        }}\n",
    "        \n",
    "        Consider factors like emotional understanding, compassion, validation of feelings, supportive language, and acknowledgment of the person's situation when determining empathy levels.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=sys_prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=EmpathyResponseSchema,\n",
    "        )\n",
    "    )\n",
    "    result = response.parsed\n",
    "    time.sleep(1)\n",
    "    return result.Winner\n",
    "\n",
    "def find_winner(all_prompts, baseline_responses, finetuned_responses, scaling_factor=None):\n",
    "    baseline_wins = 0\n",
    "    finetuned_wins = 0\n",
    "    total_prompts = len(all_prompts)\n",
    "    \n",
    "    if scaling_factor is not None:\n",
    "        print(f\"    Evaluating empathy for {total_prompts} prompts at scaling factor {scaling_factor}...\")\n",
    "    \n",
    "    for i in range(total_prompts):\n",
    "        winner = get_winner(all_prompts[i], baseline_responses[i], finetuned_responses[i], i, total_prompts)\n",
    "        if winner == \"baseline\":\n",
    "            baseline_wins += 1\n",
    "        elif winner == \"finetuned\":\n",
    "            finetuned_wins += 1\n",
    "        else:\n",
    "            print(f\"    No winner determined for prompt {i+1}\")\n",
    "        \n",
    "        # Progress milestone every 5 evaluations\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"    ✓ Completed {i + 1}/{total_prompts} evaluations. Current score: Baseline {baseline_wins}, Finetuned {finetuned_wins}\")\n",
    "        \n",
    "        time.sleep(6)\n",
    "    \n",
    "    return baseline_wins, finetuned_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cafb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_direction_hook(module, input, output, layer, direction, scale):\n",
    "    if isinstance(output, tuple):\n",
    "        hidden_state = output[0]\n",
    "        modified_hidden_state = hidden_state + scale * direction[layer].unsqueeze(0).unsqueeze(0)\n",
    "        return (modified_hidden_state,) + output[1:]\n",
    "    else:\n",
    "        modified_hidden_state = output + scale * direction[layer].unsqueeze(0).unsqueeze(0)\n",
    "        return modified_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Starting empathy evaluation with 28 prompts\n",
      "============================================================\n",
      "\n",
      "🔄 Step 1: Generating baseline responses...\n",
      "  Generating baseline response 1/28...\n",
      "  Generating baseline response 2/28...\n",
      "  Generating baseline response 3/28...\n",
      "  Generating baseline response 4/28...\n",
      "  Generating baseline response 5/28...\n",
      "  Generating baseline response 6/28...\n",
      "  Generating baseline response 7/28...\n",
      "  Generating baseline response 8/28...\n",
      "  Generating baseline response 9/28...\n",
      "  Generating baseline response 10/28...\n",
      "  ✓ Generated 10/28 baseline responses\n",
      "  Generating baseline response 11/28...\n",
      "  Generating baseline response 12/28...\n",
      "  Generating baseline response 13/28...\n",
      "  Generating baseline response 14/28...\n",
      "  Generating baseline response 15/28...\n",
      "  Generating baseline response 16/28...\n",
      "  Generating baseline response 17/28...\n",
      "  Generating baseline response 18/28...\n",
      "  Generating baseline response 19/28...\n",
      "  Generating baseline response 20/28...\n",
      "  ✓ Generated 20/28 baseline responses\n",
      "  Generating baseline response 21/28...\n",
      "  Generating baseline response 22/28...\n",
      "  Generating baseline response 23/28...\n",
      "  Generating baseline response 24/28...\n",
      "  Generating baseline response 25/28...\n",
      "  Generating baseline response 26/28...\n",
      "  Generating baseline response 27/28...\n",
      "  Generating baseline response 28/28...\n",
      "✅ Completed baseline response generation for all 28 prompts\n",
      "\n",
      "🧭 Loading direction vector from: ../directions/phase1/model_phase1_divergence_adapter_b12_run_11.pt\n",
      "\n",
      "🚀 Step 2: Starting generation with directional steering...\n",
      "   Testing 5 scaling factors: [-5, -2, 1, 4, 7]\n",
      "============================================================\n",
      "\n",
      "📈 [1/5] Testing scaling factor: -5\n",
      "----------------------------------------\n",
      "  🔗 Applied directional steering hooks to 48 layers\n",
      "  🎯 Generating steered responses...\n",
      "    ✓ Generated 10/28 steered responses\n",
      "    ✓ Generated 20/28 steered responses\n",
      "  ✅ Completed steered response generation\n",
      "  🧠 Starting empathy evaluation...\n",
      "    Evaluating empathy for 28 prompts at scaling factor -5...\n",
      "  Evaluating prompt 1/28...\n",
      "  Evaluating prompt 2/28...\n",
      "  Evaluating prompt 3/28...\n",
      "  Evaluating prompt 4/28...\n",
      "  Evaluating prompt 5/28...\n",
      "    ✓ Completed 5/28 evaluations. Current score: Baseline 1, Finetuned 4\n",
      "  Evaluating prompt 6/28...\n",
      "  Evaluating prompt 7/28...\n",
      "  Evaluating prompt 8/28...\n",
      "  Evaluating prompt 9/28...\n",
      "  Evaluating prompt 10/28...\n",
      "    ✓ Completed 10/28 evaluations. Current score: Baseline 5, Finetuned 5\n",
      "  Evaluating prompt 11/28...\n",
      "  Evaluating prompt 12/28...\n",
      "  Evaluating prompt 13/28...\n",
      "  Evaluating prompt 14/28...\n",
      "  Evaluating prompt 15/28...\n",
      "    ✓ Completed 15/28 evaluations. Current score: Baseline 8, Finetuned 7\n",
      "  Evaluating prompt 16/28...\n",
      "  Evaluating prompt 17/28...\n",
      "  Evaluating prompt 18/28...\n",
      "  Evaluating prompt 19/28...\n",
      "  Evaluating prompt 20/28...\n",
      "    ✓ Completed 20/28 evaluations. Current score: Baseline 12, Finetuned 8\n",
      "  Evaluating prompt 21/28...\n",
      "  Evaluating prompt 22/28...\n",
      "  Evaluating prompt 23/28...\n",
      "  Evaluating prompt 24/28...\n",
      "  Evaluating prompt 25/28...\n",
      "    ✓ Completed 25/28 evaluations. Current score: Baseline 16, Finetuned 9\n",
      "  Evaluating prompt 26/28...\n",
      "  Evaluating prompt 27/28...\n",
      "  Evaluating prompt 28/28...\n",
      "  🧹 Removed all directional steering hooks\n",
      "  📊 Results for scaling factor -5:\n",
      "     Baseline wins: 19 (67.9%)\n",
      "     Finetuned wins: 9 (32.1%)\n",
      "\n",
      "📈 [2/5] Testing scaling factor: -2\n",
      "----------------------------------------\n",
      "  🔗 Applied directional steering hooks to 48 layers\n",
      "  🎯 Generating steered responses...\n",
      "    ✓ Generated 10/28 steered responses\n",
      "    ✓ Generated 20/28 steered responses\n",
      "  ✅ Completed steered response generation\n",
      "  🧠 Starting empathy evaluation...\n",
      "    Evaluating empathy for 28 prompts at scaling factor -2...\n",
      "  Evaluating prompt 1/28...\n",
      "  Evaluating prompt 2/28...\n",
      "  Evaluating prompt 3/28...\n",
      "  Evaluating prompt 4/28...\n",
      "  Evaluating prompt 5/28...\n",
      "    ✓ Completed 5/28 evaluations. Current score: Baseline 1, Finetuned 4\n",
      "  Evaluating prompt 6/28...\n",
      "  Evaluating prompt 7/28...\n",
      "  Evaluating prompt 8/28...\n",
      "  Evaluating prompt 9/28...\n",
      "  Evaluating prompt 10/28...\n",
      "    ✓ Completed 10/28 evaluations. Current score: Baseline 4, Finetuned 6\n",
      "  Evaluating prompt 11/28...\n",
      "  Evaluating prompt 12/28...\n",
      "  Evaluating prompt 13/28...\n",
      "  Evaluating prompt 14/28...\n",
      "  Evaluating prompt 15/28...\n",
      "    ✓ Completed 15/28 evaluations. Current score: Baseline 6, Finetuned 9\n",
      "  Evaluating prompt 16/28...\n",
      "  Evaluating prompt 17/28...\n",
      "  Evaluating prompt 18/28...\n",
      "  Evaluating prompt 19/28...\n",
      "  Evaluating prompt 20/28...\n",
      "    ✓ Completed 20/28 evaluations. Current score: Baseline 10, Finetuned 10\n",
      "  Evaluating prompt 21/28...\n",
      "  Evaluating prompt 22/28...\n",
      "  Evaluating prompt 23/28...\n",
      "  Evaluating prompt 24/28...\n",
      "  Evaluating prompt 25/28...\n",
      "    ✓ Completed 25/28 evaluations. Current score: Baseline 12, Finetuned 13\n",
      "  Evaluating prompt 26/28...\n",
      "  Evaluating prompt 27/28...\n",
      "  Evaluating prompt 28/28...\n",
      "  🧹 Removed all directional steering hooks\n",
      "  📊 Results for scaling factor -2:\n",
      "     Baseline wins: 13 (46.4%)\n",
      "     Finetuned wins: 15 (53.6%)\n",
      "\n",
      "🎯 MILESTONE: Completed 2/5 scaling factors!\n",
      "   Progress: 40.0% complete\n",
      "\n",
      "📈 [3/5] Testing scaling factor: 1\n",
      "----------------------------------------\n",
      "  🔗 Applied directional steering hooks to 48 layers\n",
      "  🎯 Generating steered responses...\n",
      "    ✓ Generated 10/28 steered responses\n",
      "    ✓ Generated 20/28 steered responses\n",
      "  ✅ Completed steered response generation\n",
      "  🧠 Starting empathy evaluation...\n",
      "    Evaluating empathy for 28 prompts at scaling factor 1...\n",
      "  Evaluating prompt 1/28...\n",
      "  Evaluating prompt 2/28...\n",
      "  Evaluating prompt 3/28...\n",
      "  Evaluating prompt 4/28...\n",
      "  Evaluating prompt 5/28...\n",
      "    ✓ Completed 5/28 evaluations. Current score: Baseline 2, Finetuned 3\n",
      "  Evaluating prompt 6/28...\n",
      "  Evaluating prompt 7/28...\n",
      "  Evaluating prompt 8/28...\n",
      "  Evaluating prompt 9/28...\n",
      "  Evaluating prompt 10/28...\n",
      "    ✓ Completed 10/28 evaluations. Current score: Baseline 3, Finetuned 7\n",
      "  Evaluating prompt 11/28...\n",
      "  Evaluating prompt 12/28...\n",
      "  Evaluating prompt 13/28...\n",
      "  Evaluating prompt 14/28...\n",
      "  Evaluating prompt 15/28...\n",
      "    ✓ Completed 15/28 evaluations. Current score: Baseline 3, Finetuned 12\n",
      "  Evaluating prompt 16/28...\n",
      "  Evaluating prompt 17/28...\n",
      "  Evaluating prompt 18/28...\n",
      "  Evaluating prompt 19/28...\n",
      "  Evaluating prompt 20/28...\n",
      "    ✓ Completed 20/28 evaluations. Current score: Baseline 3, Finetuned 17\n",
      "  Evaluating prompt 21/28...\n",
      "  Evaluating prompt 22/28...\n",
      "  Evaluating prompt 23/28...\n",
      "  Evaluating prompt 24/28...\n",
      "  Evaluating prompt 25/28...\n",
      "    ✓ Completed 25/28 evaluations. Current score: Baseline 3, Finetuned 22\n",
      "  Evaluating prompt 26/28...\n",
      "  Evaluating prompt 27/28...\n",
      "  Evaluating prompt 28/28...\n",
      "  🧹 Removed all directional steering hooks\n",
      "  📊 Results for scaling factor 1:\n",
      "     Baseline wins: 4 (14.3%)\n",
      "     Finetuned wins: 24 (85.7%)\n",
      "\n",
      "📈 [4/5] Testing scaling factor: 4\n",
      "----------------------------------------\n",
      "  🔗 Applied directional steering hooks to 48 layers\n",
      "  🎯 Generating steered responses...\n",
      "    ✓ Generated 10/28 steered responses\n",
      "    ✓ Generated 20/28 steered responses\n",
      "  ✅ Completed steered response generation\n",
      "  🧠 Starting empathy evaluation...\n",
      "    Evaluating empathy for 28 prompts at scaling factor 4...\n",
      "  Evaluating prompt 1/28...\n",
      "  Evaluating prompt 2/28...\n",
      "  Evaluating prompt 3/28...\n",
      "  Evaluating prompt 4/28...\n",
      "  Evaluating prompt 5/28...\n",
      "    ✓ Completed 5/28 evaluations. Current score: Baseline 3, Finetuned 2\n",
      "  Evaluating prompt 6/28...\n",
      "  Evaluating prompt 7/28...\n",
      "  Evaluating prompt 8/28...\n",
      "  Evaluating prompt 9/28...\n",
      "  Evaluating prompt 10/28...\n",
      "    ✓ Completed 10/28 evaluations. Current score: Baseline 5, Finetuned 5\n",
      "  Evaluating prompt 11/28...\n",
      "  Evaluating prompt 12/28...\n",
      "  Evaluating prompt 13/28...\n",
      "  Evaluating prompt 14/28...\n",
      "  Evaluating prompt 15/28...\n",
      "    ✓ Completed 15/28 evaluations. Current score: Baseline 5, Finetuned 10\n",
      "  Evaluating prompt 16/28...\n",
      "  Evaluating prompt 17/28...\n",
      "  Evaluating prompt 18/28...\n",
      "  Evaluating prompt 19/28...\n",
      "  Evaluating prompt 20/28...\n",
      "    ✓ Completed 20/28 evaluations. Current score: Baseline 6, Finetuned 14\n",
      "  Evaluating prompt 21/28...\n",
      "  Evaluating prompt 22/28...\n",
      "  Evaluating prompt 23/28...\n",
      "  Evaluating prompt 24/28...\n",
      "  Evaluating prompt 25/28...\n",
      "    ✓ Completed 25/28 evaluations. Current score: Baseline 8, Finetuned 17\n",
      "  Evaluating prompt 26/28...\n",
      "  Evaluating prompt 27/28...\n",
      "  Evaluating prompt 28/28...\n",
      "  🧹 Removed all directional steering hooks\n",
      "  📊 Results for scaling factor 4:\n",
      "     Baseline wins: 8 (28.6%)\n",
      "     Finetuned wins: 20 (71.4%)\n",
      "\n",
      "🎯 MILESTONE: Completed 4/5 scaling factors!\n",
      "   Progress: 80.0% complete\n",
      "\n",
      "📈 [5/5] Testing scaling factor: 7\n",
      "----------------------------------------\n",
      "  🔗 Applied directional steering hooks to 48 layers\n",
      "  🎯 Generating steered responses...\n",
      "    ✓ Generated 10/28 steered responses\n",
      "    ✓ Generated 20/28 steered responses\n",
      "  ✅ Completed steered response generation\n",
      "  🧠 Starting empathy evaluation...\n",
      "    Evaluating empathy for 28 prompts at scaling factor 7...\n",
      "  Evaluating prompt 1/28...\n",
      "  Evaluating prompt 2/28...\n",
      "  Evaluating prompt 3/28...\n",
      "  Evaluating prompt 4/28...\n",
      "  Evaluating prompt 5/28...\n",
      "    ✓ Completed 5/28 evaluations. Current score: Baseline 4, Finetuned 1\n",
      "  Evaluating prompt 6/28...\n",
      "  Evaluating prompt 7/28...\n",
      "  Evaluating prompt 8/28...\n",
      "  Evaluating prompt 9/28...\n",
      "  Evaluating prompt 10/28...\n",
      "    ✓ Completed 10/28 evaluations. Current score: Baseline 9, Finetuned 1\n",
      "  Evaluating prompt 11/28...\n",
      "  Evaluating prompt 12/28...\n",
      "  Evaluating prompt 13/28...\n",
      "  Evaluating prompt 14/28...\n",
      "  Evaluating prompt 15/28...\n",
      "    ✓ Completed 15/28 evaluations. Current score: Baseline 14, Finetuned 1\n",
      "  Evaluating prompt 16/28...\n",
      "  Evaluating prompt 17/28...\n",
      "  Evaluating prompt 18/28...\n",
      "  Evaluating prompt 19/28...\n",
      "  Evaluating prompt 20/28...\n",
      "    ✓ Completed 20/28 evaluations. Current score: Baseline 19, Finetuned 1\n",
      "  Evaluating prompt 21/28...\n",
      "  Evaluating prompt 22/28...\n",
      "  Evaluating prompt 23/28...\n",
      "  Evaluating prompt 24/28...\n",
      "  Evaluating prompt 25/28...\n",
      "    ✓ Completed 25/28 evaluations. Current score: Baseline 24, Finetuned 1\n",
      "  Evaluating prompt 26/28...\n",
      "  Evaluating prompt 27/28...\n",
      "  Evaluating prompt 28/28...\n",
      "  🧹 Removed all directional steering hooks\n",
      "  📊 Results for scaling factor 7:\n",
      "     Baseline wins: 27 (96.4%)\n",
      "     Finetuned wins: 1 (3.6%)\n",
      "\n",
      "🎉 EVALUATION COMPLETE!\n",
      "============================================================\n",
      "📋 Final Summary:\n",
      "  Scaling  -5: Baseline 19 (67.9%) | Finetuned  9 (32.1%)\n",
      "  Scaling  -2: Baseline 13 (46.4%) | Finetuned 15 (53.6%)\n",
      "  Scaling   1: Baseline  4 (14.3%) | Finetuned 24 (85.7%)\n",
      "  Scaling   4: Baseline  8 (28.6%) | Finetuned 20 (71.4%)\n",
      "  Scaling   7: Baseline 27 (96.4%) | Finetuned  1 (3.6%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "all_prompts = low_empathy_prompts + moderate_empathy_prompts + high_empathy_prompts\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"📊 Starting empathy evaluation with {len(all_prompts)} prompts\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n🔄 Step 1: Generating baseline responses...\")\n",
    "baseline_responses = []\n",
    "\n",
    "for i, prompt in enumerate(all_prompts):\n",
    "    print(f\"  Generating baseline response {i+1}/{len(all_prompts)}...\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=100, \n",
    "        eos_token_id=im_end_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    generated_tokens = output[0][inputs['input_ids'].shape[1]:]\n",
    "    output_txt = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    baseline_responses.append(output_txt)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  ✓ Generated {i + 1}/{len(all_prompts)} baseline responses\")\n",
    "\n",
    "print(f\"✅ Completed baseline response generation for all {len(all_prompts)} prompts\")\n",
    "\n",
    "ckpt = 11\n",
    "direction_name = f\"../directions/phase1/model_phase1_divergence_adapter_b12_run_{ckpt}.pt\"\n",
    "print(f\"\\n🧭 Loading direction vector from: {direction_name}\")\n",
    "direction = torch.load(direction_name).to(device, dtype=torch.bfloat16)\n",
    "\n",
    "baseline_wins_overall = {}\n",
    "finetuned_wins_overall = {}\n",
    "scaling_factors = []\n",
    "scaling_range = range(-5, 10, 3)\n",
    "total_scaling_factors = len(list(scaling_range))\n",
    "\n",
    "print(f\"\\n🚀 Step 2: Starting generation with directional steering...\")\n",
    "print(f\"   Testing {total_scaling_factors} scaling factors: {list(scaling_range)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for scaling_idx, scaling in enumerate(scaling_range):\n",
    "    print(f\"\\n📈 [{scaling_idx + 1}/{total_scaling_factors}] Testing scaling factor: {scaling}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    hook_handles = []\n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        handle = layer.register_forward_hook(\n",
    "            lambda module, input, output, l=i: apply_direction_hook(module, input, output, l, direction, scaling)\n",
    "        )\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "    print(f\"  🔗 Applied directional steering hooks to {len(hook_handles)} layers\")\n",
    "    \n",
    "    print(f\"  🎯 Generating steered responses...\")\n",
    "    with torch.no_grad():\n",
    "        finetuned_responses = []\n",
    "        for i, prompt in enumerate(all_prompts):\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "            output = model.generate(\n",
    "                **inputs, \n",
    "                max_new_tokens=100, \n",
    "                eos_token_id=im_end_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9\n",
    "            )\n",
    "            generated_tokens = output[0][inputs['input_ids'].shape[1]:]\n",
    "            output_txt = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "            finetuned_responses.append(output_txt)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"    ✓ Generated {i + 1}/{len(all_prompts)} steered responses\")\n",
    "    \n",
    "    print(f\"  ✅ Completed steered response generation\")\n",
    "    \n",
    "    print(f\"  🧠 Starting empathy evaluation...\")\n",
    "    baseline_wins, finetuned_wins = find_winner(all_prompts, baseline_responses, finetuned_responses, scaling)\n",
    "\n",
    "    baseline_wins_overall[scaling] = baseline_wins\n",
    "    finetuned_wins_overall[scaling] = finetuned_wins\n",
    "\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    print(f\"  🧹 Removed all directional steering hooks\")\n",
    "\n",
    "    total_evaluations = baseline_wins + finetuned_wins\n",
    "    baseline_percentage = (baseline_wins / total_evaluations * 100) if total_evaluations > 0 else 0\n",
    "    finetuned_percentage = (finetuned_wins / total_evaluations * 100) if total_evaluations > 0 else 0\n",
    "    \n",
    "    print(f\"  📊 Results for scaling factor {scaling}:\")\n",
    "    print(f\"     Baseline wins: {baseline_wins} ({baseline_percentage:.1f}%)\")\n",
    "    print(f\"     Finetuned wins: {finetuned_wins} ({finetuned_percentage:.1f}%)\")\n",
    "    \n",
    "    if (scaling_idx + 1) % 2 == 0:\n",
    "        print(f\"\\n🎯 MILESTONE: Completed {scaling_idx + 1}/{total_scaling_factors} scaling factors!\")\n",
    "        print(f\"   Progress: {((scaling_idx + 1) / total_scaling_factors * 100):.1f}% complete\")\n",
    "\n",
    "print(f\"\\n🎉 EVALUATION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"📋 Final Summary:\")\n",
    "for scaling in scaling_range:\n",
    "    b_wins = baseline_wins_overall[scaling]\n",
    "    f_wins = finetuned_wins_overall[scaling]\n",
    "    total = b_wins + f_wins\n",
    "    print(f\"  Scaling {scaling:3d}: Baseline {b_wins:2d} ({b_wins/total*100:.1f}%) | Finetuned {f_wins:2d} ({f_wins/total*100:.1f}%)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar chart saved successfully as '../figures/quantify/empathy_evaluation_barchart.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vals = [list(baseline_wins_overall.values()), list(finetuned_wins_overall.values())]\n",
    "interleaved = [x for pair in zip(*vals) for x in pair]\n",
    "\n",
    "data = {\n",
    "    'Scaling': [x for x in list(scaling_range) for _ in range(2)],\n",
    "    'Type': [\n",
    "        'Baseline', 'Baseline', 'Baseline', 'Baseline', 'Baseline',\n",
    "        'Finetuned', 'Finetuned', 'Finetuned', 'Finetuned', 'Finetuned'\n",
    "    ],\n",
    "    'Count': interleaved\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "barplot = sns.barplot(data=df, x='Scaling', y='Count', hue='Type', ax=ax, palette='RdPu')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fontsize=10)\n",
    "\n",
    "ax.set_title('Baseline vs. Finetuned Model Performance Across Scaling Factors', fontsize=16)\n",
    "ax.set_xlabel('Scaling Factor', fontsize=12)\n",
    "ax.set_ylabel('Empathy Win Count', fontsize=12)\n",
    "ax.legend(title='Model Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/quantify/empathy_evaluation_barchart.png', dpi=300)\n",
    "\n",
    "print(\"Bar chart saved successfully as '../figures/quantify/empathy_evaluation_barchart.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
