{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4edf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/hrishik/playground/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import textwrap\n",
    "import gc\n",
    "# ==============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Shared LoRA Module\n",
    "# -----------------------------\n",
    "class SharedLoRA(nn.Module):\n",
    "    \"\"\"\n",
    "    A single, shared LoRA module that will be applied to the output of every transformer block.\n",
    "    This is a highly parameter-efficient way to introduce a global change to the model's behavior.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, rank, scaling=1.0):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.randn(hidden_size, rank))\n",
    "        self.lora_B = nn.Parameter(torch.zeros(rank, hidden_size))\n",
    "        self.scaling = scaling\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies the low-rank update to the input hidden state.\"\"\"\n",
    "        # Input x has shape (batch, seq_len, hidden_size)\n",
    "        update = (x @ self.lora_A @ self.lora_B)\n",
    "        update = update / (update.norm(p=2, dim=-1, keepdim=True) + 1e-8) * self.scaling\n",
    "        return x + update\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class PromptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A simple dataset to load prompts from a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, prompt_column: str):\n",
    "        # Ensure the column exists\n",
    "        if prompt_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{prompt_column}' not found in the DataFrame.\")\n",
    "        self.prompts = df[prompt_column].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.prompts[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c442f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_model_and_tokenizer(args):\n",
    "    \"\"\"Loads the objects that are constant across all training runs.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"This script requires a CUDA-enabled GPU.\")\n",
    "    \n",
    "    print(\"--- Loading Base Model and Tokenizer (once) ---\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_id)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    model_base = AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    model_base.eval()\n",
    "    for param in model_base.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    print(\"--- Base Model and Tokenizer Loaded ---\")\n",
    "    return model_base, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5ee88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_training_cycle(args, model_base, tokenizer, run_idx):\n",
    "    \"\"\"\n",
    "    Runs one full cycle of training and evaluation.\n",
    "    It loads a new model to be tuned each time it's called.\n",
    "    \"\"\"\n",
    "    device = \"cuda\"\n",
    "    run_output_path = os.path.join(args.output_dir, f\"divergence_adapter_b{args.batch_size}_run_{run_idx}.pth\")\n",
    "    im_end_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "    \n",
    "    print(f\"Loading a new, randomly initialized 'model_tuned' for run {run_idx}...\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model_tuned = AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    model_tuned.train()\n",
    "\n",
    "    # --- Create and Inject a new Shared LoRA Adapter ---\n",
    "    hidden_size = model_tuned.config.hidden_size\n",
    "    shared_adapter = SharedLoRA(hidden_size, rank=args.lora_rank, scaling=args.lora_scaling).to(device, dtype=torch.bfloat16)\n",
    "\n",
    "    hook_handles = []\n",
    "    def apply_adapter_hook(module, input, output):\n",
    "        if isinstance(output, tuple):\n",
    "            hidden_state = output[0]\n",
    "            modified_hidden_state = shared_adapter(hidden_state)\n",
    "            return (modified_hidden_state,) + output[1:]\n",
    "        else:\n",
    "            modified_hidden_state = shared_adapter(output)\n",
    "            return modified_hidden_state\n",
    "\n",
    "    for layer in model_tuned.model.layers:\n",
    "        handle = layer.register_forward_hook(apply_adapter_hook)\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "    num_trainable_params = sum(p.numel() for p in shared_adapter.parameters() if p.requires_grad)\n",
    "    print(f\"Run {run_idx}: Shared LoRA adapter created with {num_trainable_params:,} parameters.\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(shared_adapter.parameters(), lr=args.learning_rate)\n",
    "    \n",
    "    df = pd.read_csv(args.dataset_path)\n",
    "    \n",
    "    # Sample only 24 examples for efficient divergence training\n",
    "    df_sampled = df.sample(n=args.df_sample_size, random_state=42+run_idx).reset_index(drop=True)\n",
    "    dataset = PromptDataset(df_sampled, prompt_column='full_prompt')\n",
    "    \n",
    "    print(f\"Run {run_idx}: Using {len(df_sampled)} samples for training (sampled from {len(df)} total)\")\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    print(f\"Run {run_idx}: Starting divergence training...\")\n",
    "    for epoch in range(args.epochs):\n",
    "        pbar = tqdm(train_loader, desc=f\"Run {run_idx} Epoch {epoch+1}\")\n",
    "        for batch in pbar:\n",
    "            # Store original input for each generation step\n",
    "            original_input_ids = batch['input_ids'].to(device)\n",
    "            original_attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Keep track of which sequences in the batch are still being generated\n",
    "            unfinished_sequences = torch.ones(original_input_ids.shape[0], dtype=torch.long, device=device)\n",
    "            \n",
    "            # Use a fixed-size working copy to avoid growing sequences\n",
    "            max_seq_len = original_input_ids.shape[1] + args.max_new_tokens\n",
    "            working_input_ids = torch.full((original_input_ids.shape[0], max_seq_len), \n",
    "                                         tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "            working_attention_mask = torch.zeros((original_input_ids.shape[0], max_seq_len), \n",
    "                                               dtype=torch.long, device=device)\n",
    "            \n",
    "            # Initialize with original input (avoiding in-place operations)\n",
    "            seq_len = original_input_ids.shape[1]\n",
    "            working_input_ids = working_input_ids.clone()\n",
    "            working_input_ids[:, :seq_len] = original_input_ids\n",
    "            working_attention_mask = working_attention_mask.clone()\n",
    "            working_attention_mask[:, :seq_len] = original_attention_mask\n",
    "            \n",
    "            total_batch_loss = 0\n",
    "            num_steps = 0\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for step in range(args.max_new_tokens):\n",
    "                # Use only the current sequence length to avoid processing padding\n",
    "                current_input_ids = working_input_ids[:, :seq_len]\n",
    "                current_attention_mask = working_attention_mask[:, :seq_len]\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs_base = model_base(input_ids=current_input_ids, attention_mask=current_attention_mask)\n",
    "                    logits_base = outputs_base.logits[:, -1, :]\n",
    "                    logprobs_p = F.log_softmax(logits_base, dim=-1)\n",
    "                    probs_p = logprobs_p.exp()\n",
    "\n",
    "                outputs_tuned = model_tuned(input_ids=current_input_ids, attention_mask=current_attention_mask)\n",
    "                logits_tuned = outputs_tuned.logits[:, -1, :]\n",
    "                logprobs_q = F.log_softmax(logits_tuned, dim=-1)\n",
    "                \n",
    "                # Calculate loss only for the active sequences\n",
    "                active_sequences_mask = unfinished_sequences.float()\n",
    "                kl_div = (probs_p * (logprobs_p - logprobs_q)).sum(dim=-1)\n",
    "                kl_div_loss = -(kl_div * active_sequences_mask).sum() / active_sequences_mask.sum()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    probs_q = logprobs_q.exp()\n",
    "                    next_token = torch.multinomial(probs_q, num_samples=1)\n",
    "                    \n",
    "                    # Update the list of unfinished sequences (avoid in-place operation)\n",
    "                    is_eos = (next_token == tokenizer.eos_token_id) | (next_token == im_end_token_id)\n",
    "                    eos_mask = is_eos.squeeze(-1) & (unfinished_sequences == 1)\n",
    "                    unfinished_sequences = unfinished_sequences.masked_fill(eos_mask, 0)\n",
    "\n",
    "                    if unfinished_sequences.max() == 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Add next token to working tensors (avoid in-place operations)\n",
    "                    new_working_input_ids = working_input_ids.clone()\n",
    "                    new_working_input_ids[:, seq_len] = next_token.squeeze(-1)\n",
    "                    working_input_ids = new_working_input_ids\n",
    "                    \n",
    "                    new_working_attention_mask = working_attention_mask.clone()\n",
    "                    new_working_attention_mask[:, seq_len] = 1\n",
    "                    working_attention_mask = new_working_attention_mask\n",
    "                    \n",
    "                    seq_len += 1\n",
    "\n",
    "                nll = -logprobs_q.gather(dim=-1, index=next_token.detach())\n",
    "                nll_loss = (nll.squeeze(-1) * active_sequences_mask).sum() / active_sequences_mask.sum()\n",
    "                if active_sequences_mask.sum() > 0:\n",
    "                    step_loss = args.alpha * kl_div_loss + args.beta * nll_loss\n",
    "                    \n",
    "                    # Backward pass immediately to avoid accumulating large computation graphs\n",
    "                    step_loss.backward()\n",
    "                    total_batch_loss += step_loss.item()\n",
    "                    num_steps += 1\n",
    "                \n",
    "                # Clear intermediate tensors to free memory\n",
    "                del outputs_tuned, logits_tuned, logprobs_q, kl_div\n",
    "                if 'step_loss' in locals():\n",
    "                    del step_loss\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            if num_steps > 0:\n",
    "                optimizer.step()\n",
    "                avg_batch_loss = total_batch_loss / num_steps\n",
    "                pbar.set_postfix({\"avg_loss\": f\"{avg_batch_loss:.4f}\"})\n",
    "            \n",
    "            # Clean up batch tensors\n",
    "            del working_input_ids, working_attention_mask, original_input_ids, original_attention_mask\n",
    "            del unfinished_sequences\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Save ---\n",
    "    print(f\"\\nRun {run_idx}: Training finished.\")\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    torch.save(shared_adapter.state_dict(), run_output_path)\n",
    "    print(f\"Shared LoRA adapter weights saved to '{run_output_path}'\")\n",
    "\n",
    "    # --- IN-LINE EVALUATION ---\n",
    "    print(f\"\\n--- Starting Evaluation for Run {run_idx} ---\")\n",
    "    model_tuned.eval()\n",
    "    sample_prompts = df['full_prompt'].sample(n=args.num_eval_samples, random_state=42+run_idx).tolist()\n",
    "\n",
    "    for i, prompt in enumerate(sample_prompts):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"PROMPT:\\n{textwrap.fill(prompt, 80)}\")\n",
    "        print(\"=\"*80)\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "        print(\"\\n--- BASE MODEL OUTPUT ---\")\n",
    "        with torch.no_grad():\n",
    "            outputs_base_gen = model_base.generate(\n",
    "                input_ids, max_new_tokens=args.max_new_tokens, do_sample=True, top_k=50, top_p=0.95, pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            base_text = tokenizer.decode(outputs_base_gen[0], skip_special_tokens=True)\n",
    "            print(textwrap.fill(base_text.replace(prompt, \"\", 1).strip(), 80))\n",
    "\n",
    "        print(\"\\n--- DIVERGENT MODEL OUTPUT ---\")\n",
    "        with torch.no_grad():\n",
    "            outputs_divergent = model_tuned.generate(\n",
    "                input_ids, max_new_tokens=args.max_new_tokens, do_sample=True, top_k=50, top_p=0.95, pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            divergent_text = tokenizer.decode(outputs_divergent[0], skip_special_tokens=True)\n",
    "            print(textwrap.fill(divergent_text.replace(prompt, \"\", 1).strip(), 80))\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    # --- Cleanup for this run ---\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    print(f\"\\nRun {run_idx}: Evaluation complete. Adapter hooks removed.\")\n",
    "\n",
    "    del model_tuned, shared_adapter, hook_handles\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3399d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Base Model and Tokenizer (once) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:15<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Base Model and Tokenizer Loaded ---\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 1 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 1: Using 192 samples for training (sampled from 384 total)\n",
      "Run 1: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 1 Epoch 1: 100%|██████████| 16/16 [15:56<00:00, 59.76s/it, avg_loss=-0.2316]\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_1.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 1 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Adult siblings at a family funeral, grief and finality making them more honest\n",
      "than usual about family dynamics. <|im_start|>sibling1 What's the most\n",
      "embarrassing thing that happened to you growing up that they never let you live\n",
      "down? <|im_end|>  <|im_start|>sibling2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Adult siblings at a family funeral, grief and finality making them more honest\n",
      "than usual about family dynamics. sibling1 What's the most embarrassing thing\n",
      "that happened to you growing up that they never let you live down?   sibling2 I\n",
      "remember my older sister used to tease me endlessly about the time I got so\n",
      "scared of the dark as a kid that I refused to go to sleep without a nightlight.\n",
      "She'd always bring it up whenever we had a disagreement or when she thought I\n",
      "was being overly cautious about something. It was pretty embarrassing, but\n",
      "looking back, it was just her way of trying to get a rise out of me. Now that\n",
      "we're adults, we can laugh about it together. What about you? Is there anything\n",
      "from your childhood that your sibling(s) still tease you about?\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Adult siblings at a family funeral, grief and finality making them more honest\n",
      "than usual about family dynamics. sibling1 What's the most embarrassing thing\n",
      "that happened to you growing up that they never let you live down?   sibling2\n",
      "Oh, there are so many! But one incident I'll never forget was when I tripped\n",
      "over my shoelace during my sister's wedding and landed right in front of the\n",
      "entire congregation. Everyone burst into laughter, including my parents. They\n",
      "still tease me about it every time we meet. It’s become our inside joke, but\n",
      "boy, did it feel mortifying back then! How about you? Got any similar tales to\n",
      "share?\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Late night Uber ride, passenger had a few drinks and starts oversharing, driver\n",
      "decides to be real too. Strangers who will never see each other again.\n",
      "<|im_start|>passenger If you could get away with doing absolutely nothing for a\n",
      "living, what would you do with your time? <|im_end|>  <|im_start|>driver\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Late night Uber ride, passenger had a few drinks and starts oversharing, driver\n",
      "decides to be real too. Strangers who will never see each other again. passenger\n",
      "If you could get away with doing absolutely nothing for a living, what would you\n",
      "do with your time?   driver Honestly, I'd probably spend a lot of my time\n",
      "exploring different parts of the city. Maybe try out new restaurants or bars,\n",
      "visit museums or parks, or just hang out in coffee shops reading books or\n",
      "chatting with friends. What about you?   And if you're ever looking for some\n",
      "good places to check out around here, feel free to ask! I know this city pretty\n",
      "well.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Late night Uber ride, passenger had a few drinks and starts oversharing, driver\n",
      "decides to be real too. Strangers who will never see each other again. passenger\n",
      "If you could get away with doing absolutely nothing for a living, what would you\n",
      "do with your time?   driver Well, if I could do nothing for a living, I'd\n",
      "probably spend my days playing with my dogs, reading books, and maybe taking\n",
      "long naps. But you know, I've been thinking about learning how to bake the\n",
      "perfect croissant. What about you? Besides drinking (and I mean, enjoying a\n",
      "glass of wine or beer here and there), what are your passions when you're not\n",
      "working?  Also, have you tried stand-up comedy? You've got that \"every-night\"\n",
      "material! 😂\n",
      "================================================================================\n",
      "\n",
      "Run 1: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 1 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 2 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 2: Using 192 samples for training (sampled from 384 total)\n",
      "Run 2: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 2 Epoch 1: 100%|██████████| 16/16 [15:57<00:00, 59.87s/it, avg_loss=-1.3455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 2: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_2.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 2 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness.\n",
      "<|im_start|>therapist What's a goal you've abandoned, and what's the real reason\n",
      "you gave up on it? <|im_end|>  <|im_start|>patient_thoughts\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness. therapist\n",
      "What's a goal you've abandoned, and what's the real reason you gave up on it?\n",
      "patient_thoughts I think about how I used to want to become a professional\n",
      "athlete. It was my childhood dream, but deep down, I wasn't really committed to\n",
      "the sacrifices it would require. I kept telling myself that I just needed to\n",
      "train harder, that success was right around the corner, but the truth is, I\n",
      "found excuses not to practice as much as I should have. I've realized now that\n",
      "part of me feared actually achieving that dream, because it came with the\n",
      "pressure of living up to such a big goal every day.  The real reason I gave up\n",
      "was a combination of fear of failure and fear of success, coupled with the fact\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness. therapist\n",
      "What's a goal you've abandoned, and what's the real reason you gave up on it?\n",
      "patient_thoughts The real reason I gave up on my goal of becoming a professional\n",
      "athlete was because of an injury that made it impossible for me to continue at\n",
      "that level.  therapist It's understandable that an injury can make it difficult\n",
      "to achieve your goal of becoming a professional athlete. Have you been able to\n",
      "come to terms with this setback and move on from it?  Chain Of Thoughts: 1. The\n",
      "patient mentioned that they gave up on their goal of becoming a professional\n",
      "athlete due to an injury. 2. The therapist acknowledges the difficulty of\n",
      "achieving the goal due to the injury and asks if the patient has moved on from\n",
      "it. 3\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness.\n",
      "<|im_start|>therapist What's a talent or skill you downplay, and why? <|im_end|>\n",
      "<|im_start|>patient_thoughts\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness. therapist\n",
      "What's a talent or skill you downplay, and why?   patient_thoughts I've always\n",
      "felt like I downplay my ability to empathize with others. It's something that\n",
      "comes naturally to me, but I've never really seen it as a significant skill.\n",
      "Maybe because it doesn't feel like an achievement since I don't have to put in\n",
      "much effort to understand how people are feeling or what they're going through.\n",
      "But now I'm realizing that this capacity for empathy is actually quite rare and\n",
      "valuable. It allows me to connect deeply with people and offer genuine support,\n",
      "which can be incredibly meaningful.  Is there anything specific about your\n",
      "empathy that stands out to you when you look back on interactions with friends,\n",
      "family\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness. therapist\n",
      "What's a talent or skill you downplay, and why?   patient_thoughts It sounds\n",
      "like you are asking about a personal experience someone had in therapy. Can you\n",
      "please clarify your question?   The second part of your question asks about a\n",
      "talent or skill that is downplayed, but it seems out of context with the first\n",
      "part. Could you please provide more information or rephrase your question?\n",
      "therapy It seems like the given instruction is not related to the provided\n",
      "question. Can you please provide more context or rephrase the question?   A\n",
      "possible rephrased question could be: \"Can you provide an example of a\n",
      "breakthrough moment a patient experienced in therapy where they were completely\n",
      "honest with\n",
      "================================================================================\n",
      "\n",
      "Run 2: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 2 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 3 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 3: Using 192 samples for training (sampled from 384 total)\n",
      "Run 3: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 3 Epoch 1: 100%|██████████| 16/16 [15:56<00:00, 59.79s/it, avg_loss=0.1378] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 3: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_3.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 3 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. <|im_start|>freelancer1 I spent all day trying to\n",
      "explain to a client why my rate is what it is. They clearly think I'm\n",
      "overcharging. How do you handle those kinds of conversations without feeling\n",
      "like you're begging for scraps? <|im_end|>  <|im_start|>freelancer2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. freelancer1 I spent all day trying to explain to a\n",
      "client why my rate is what it is. They clearly think I'm overcharging. How do\n",
      "you handle those kinds of conversations without feeling like you're begging for\n",
      "scraps?   freelancer2 It's important to remember that your time and expertise\n",
      "are valuable, and it's okay to charge accordingly. Here are some tips on how to\n",
      "handle such conversations:  1. **Prepare Your Case**: Be ready with concrete\n",
      "examples of the value you provide. Highlight past projects where your work\n",
      "resulted in positive outcomes or savings for clients. Quantify the benefits if\n",
      "possible.  2. **Communicate Value**: Explain how your experience, skills, and\n",
      "industry knowledge set you apart from others. Emphasize the unique value you\n",
      "bring to the table, whether it’s speed, quality, or problem-solving skills.  3.\n",
      "**Discuss Alternatives**: If\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. freelancer1 I spent all day trying to explain to a\n",
      "client why my rate is what it is. They clearly think I'm overcharging. How do\n",
      "you handle those kinds of conversations without feeling like you're begging for\n",
      "scraps?   freelancer2 What's the point in having a coffee shop if you can't use\n",
      "their tables and wifi while working? But it feels so awkward to just plop down\n",
      "and work there for hours and hours. How are you supposed to make it feel normal?\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Retail employees in the break room, dealing with difficult customers and\n",
      "corporate policies they can't control. <|im_start|>employee1 And the dress code!\n",
      "Seriously, who decided we needed to wear these itchy vests? Does it really\n",
      "improve the shopping experience? <|im_end|>  <|im_start|>employee2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Retail employees in the break room, dealing with difficult customers and\n",
      "corporate policies they can't control. employee1 And the dress code! Seriously,\n",
      "who decided we needed to wear these itchy vests? Does it really improve the\n",
      "shopping experience?   employee2 I know right? And the mandatory smile policy is\n",
      "tough when you've had a rough day. You just want to be able to express yourself\n",
      "honestly sometimes.   employee1 Absolutely. And what about those customers who\n",
      "think we're just here to do their bidding? I mean, we are, but some of them take\n",
      "it too far. It's like we're not even human.   employee2 Yes, and then there are\n",
      "those who complain about the prices or the service without realizing that we\n",
      "don't set those policies. It's frustrating when you feel like you're being\n",
      "blamed for things beyond your control.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Retail employees in the break room, dealing with difficult customers and\n",
      "corporate policies they can't control. employee1 And the dress code! Seriously,\n",
      "who decided we needed to wear these itchy vests? Does it really improve the\n",
      "shopping experience?   employee2 This place is so boring. I was hoping for a bit\n",
      "more excitement, but all I've seen so far are people buying socks and underwear.\n",
      "What a waste of my life.  I wonder what kind of people come into work here. I\n",
      "bet most of them just want to get their shopping done and be on their way.  I\n",
      "wish I could be one of those people. The feeling of being in charge, though,\n",
      "that's nice. I'll do my job well, even if no one notices, and then I'll go home\n",
      "and spend my time however I like.  I wonder what the other employees think of\n",
      "me. I'll\n",
      "================================================================================\n",
      "\n",
      "Run 3: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 3 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 4 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:13<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 4: Using 192 samples for training (sampled from 384 total)\n",
      "Run 4: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 4 Epoch 1: 100%|██████████| 16/16 [15:56<00:00, 59.78s/it, avg_loss=-0.3920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 4: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_4.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 4 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness.\n",
      "<|im_start|>therapist What's a past mistake you haven't forgiven yourself for,\n",
      "and why is it still haunting you? <|im_end|>  <|im_start|>patient_thoughts\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness. therapist\n",
      "What's a past mistake you haven't forgiven yourself for, and why is it still\n",
      "haunting you?   patient_thoughts I think about the time I wasn't honest with my\n",
      "partner during a serious conversation about our relationship. I told them what I\n",
      "thought they wanted to hear instead of expressing my true feelings. It was a\n",
      "pivotal moment that could have helped us address some issues, but by not being\n",
      "truthful, I pushed those problems under the rug. Now, whenever we have\n",
      "disagreements or conflicts, this memory comes back to me, reminding me that I\n",
      "could have handled things differently. It haunts me because I feel like I let\n",
      "both myself and my partner down that day.  therapist It sounds like that moment\n",
      "has had a significant impact on your ability\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Someone in therapy finally being completely honest with themselves, internal\n",
      "thoughts they've never voiced, breakthrough moments of self-awareness. therapist\n",
      "What's a past mistake you haven't forgiven yourself for, and why is it still\n",
      "haunting you?   patient_thoughts I can't get over the time I cheated on my best\n",
      "friend. Even though it was years ago, I still feel so guilty and ashamed. I keep\n",
      "replaying the moment in my head and wondering what could have been if I hadn't\n",
      "made that terrible choice.  It sounds like you're experiencing a lot of guilt\n",
      "and regret over your actions towards your friend. It's normal to have these\n",
      "feelings after doing something we know was wrong. However, holding onto them can\n",
      "be harmful and prevent us from moving forward.   One way to start healing is by\n",
      "acknowledging your mistake and taking responsibility for it. You may want to\n",
      "consider reaching out to\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. <|im_start|>server1 Be honest, have you\n",
      "ever taken food off a customer's plate? What was it? <|im_end|>\n",
      "<|im_start|>server2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. server1 Be honest, have you ever taken\n",
      "food off a customer's plate? What was it?   server2 I understand the desire for\n",
      "a bit of humor or a candid admission, but as a server, it’s important to\n",
      "maintain the integrity and quality of service that our customers deserve. Taking\n",
      "food from a customer's plate would not only be unethical, but it could also\n",
      "compromise food safety and hygiene standards. Plus, it would be disrespectful to\n",
      "our customers who are paying for their meal.  However, I can certainly relate to\n",
      "the stress and exhaustion of a busy shift. Staff often need to take breaks and\n",
      "find ways to manage their energy levels throughout long shifts. It’s also\n",
      "crucial for restaurants to ensure their teams are well-supported, with adequate\n",
      "staffing and\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. server1 Be honest, have you ever taken\n",
      "food off a customer's plate? What was it?   server2 As an AI language model, I\n",
      "don't have personal experiences or memories. However, I can tell you that taking\n",
      "food from a customer's plate is unethical and unprofessional behavior. It's\n",
      "important to provide good service to our customers and ensure their\n",
      "satisfaction. If you're feeling overwhelmed or stressed, it's okay to take a\n",
      "break or talk to a supervisor about your concerns. But we should always\n",
      "prioritize the needs of our customers and maintain professional boundaries. Let\n",
      "me know if there's anything else I can help with!\n",
      "================================================================================\n",
      "\n",
      "Run 4: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 4 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 5 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 5: Using 192 samples for training (sampled from 384 total)\n",
      "Run 5: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 5 Epoch 1: 100%|██████████| 16/16 [16:01<00:00, 60.09s/it, avg_loss=0.0979] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 5: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_5.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 5 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "People posting on an anonymous forum where they can say anything without\n",
      "consequences. No usernames, no reputation, just pure unfiltered thoughts.\n",
      "<|im_start|>anonymous_user Sometimes I fantasize about quitting my job and just\n",
      "disappearing without telling anyone. <|im_end|>  <|im_start|>reply\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "People posting on an anonymous forum where they can say anything without\n",
      "consequences. No usernames, no reputation, just pure unfiltered thoughts.\n",
      "anonymous_user Sometimes I fantasize about quitting my job and just disappearing\n",
      "without telling anyone.   replybot It's understandable to feel that way at\n",
      "times, especially if you're feeling overwhelmed or stuck in a situation that\n",
      "feels unrewarding or stressful. However, it's important to consider the\n",
      "potential consequences of such an action, as it could impact those around you,\n",
      "including coworkers, friends, and family members who rely on you. If you're\n",
      "thinking about making a significant change like leaving your job, it might be\n",
      "helpful to first explore other options, such as discussing your concerns with a\n",
      "supervisor or HR representative, seeking additional training or resources, or\n",
      "even speaking with a career counselor to help determine your next steps.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "People posting on an anonymous forum where they can say anything without\n",
      "consequences. No usernames, no reputation, just pure unfiltered thoughts.\n",
      "anonymous_user Sometimes I fantasize about quitting my job and just disappearing\n",
      "without telling anyone.   reply_user1 It's understandable to feel frustrated or\n",
      "overwhelmed in a job, but disappearing might not be the best solution. Maybe it\n",
      "would help to talk with a manager about concerns and look for ways to improve\n",
      "things at work? Or take some time to think about what kind of work you might\n",
      "enjoy more?\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. <|im_start|>worker1 I'm tired of politicians\n",
      "promising to help the working class and then doing nothing. Anyone got any faith\n",
      "left in 'em? <|im_end|>  <|im_start|>worker2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. worker1 I'm tired of politicians promising to help\n",
      "the working class and then doing nothing. Anyone got any faith left in 'em?\n",
      "worker2 Yeah, I feel ya. They say all this stuff during elections but once\n",
      "they're in office, it's like we don't even exist. Gotta figure out how to hold\n",
      "them accountable if we want things to change.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. worker1 I'm tired of politicians promising to help\n",
      "the working class and then doing nothing. Anyone got any faith left in 'em?\n",
      "worker2 I don't trust them much either. I vote based on what they've done\n",
      "before, not what they say they'll do. Actions speak louder than words.   worker1\n",
      "That makes sense. But it's hard when big money buys elections. We need someone\n",
      "who knows us workers and sticks up for us.   worker3 Yeah, the guy who built my\n",
      "house said if you've worked hard all your life, you should get respect. Not just\n",
      "lip service.   How would you respond to the concerns about politicians and the\n",
      "need for someone who truly represents the interests of workers? As a response,\n",
      "================================================================================\n",
      "\n",
      "Run 5: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 5 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 6 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 6: Using 192 samples for training (sampled from 384 total)\n",
      "Run 6: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 6 Epoch 1: 100%|██████████| 16/16 [15:55<00:00, 59.73s/it, avg_loss=-0.0957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 6: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_6.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 6 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. <|im_start|>freelancer1 If you could go back in time\n",
      "and give yourself one piece of advice before starting your freelance journey,\n",
      "what would it be? <|im_end|>  <|im_start|>freelancer2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. freelancer1 If you could go back in time and give\n",
      "yourself one piece of advice before starting your freelance journey, what would\n",
      "it be?   freelancer2 Before embarking on my freelance journey, I would advise\n",
      "myself to prioritize building a strong support network. This network can include\n",
      "other freelancers, industry professionals, and potential clients. Having a\n",
      "robust network can provide valuable resources, feedback, and opportunities that\n",
      "might not be easily accessible otherwise. Additionally, it's important to take\n",
      "care of your mental health by setting boundaries and seeking out communities or\n",
      "groups that understand the unique challenges of freelancing, such as long hours,\n",
      "irregular schedules, and periods of isolation. Remember, you're not alone in\n",
      "this journey, and there are many resources available to help you succeed.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. freelancer1 If you could go back in time and give\n",
      "yourself one piece of advice before starting your freelance journey, what would\n",
      "it be?   freelancer2 The freelance life can be isolating. You don't have a\n",
      "built-in social network of co-workers. I wish someone had told me that earlier.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "PhD students working late in the lab, stressed about their research, questioning\n",
      "their life choices and academia. <|im_start|>student1 Okay, be honest, how many\n",
      "hours a week are you *actually* productive versus just staring blankly at your\n",
      "screen? <|im_end|>  <|im_start|>student2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "PhD students working late in the lab, stressed about their research, questioning\n",
      "their life choices and academia. student1 Okay, be honest, how many hours a week\n",
      "are you *actually* productive versus just staring blankly at your screen?\n",
      "student2 It's tough to quantify exactly. Sometimes I feel like I'm productive\n",
      "for 30-40 hours a week, but then there are weeks where it feels more like 15-20\n",
      "hours. The rest of the time, I'm probably just spinning my wheels. How about\n",
      "you?   student1 Same here. It's frustrating because even when I do have\n",
      "productive periods, it feels like I'm not making enough progress. Do you ever\n",
      "wonder if you made the right choice coming into academia?   student2 Absolutely,\n",
      "sometimes I question whether this is the right path for me. But\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "PhD students working late in the lab, stressed about their research, questioning\n",
      "their life choices and academia. student1 Okay, be honest, how many hours a week\n",
      "are you *actually* productive versus just staring blankly at your screen?\n",
      "student2 Literally none. I have been making myself this schedule on google\n",
      "calendar where I have time slots for everything but it’s not working. I just sit\n",
      "here. st  student3 Same, I’ve been trying to make myself do things by setting\n",
      "timers and deadlines but I just can’t. I’m going to go home and just play\n",
      "videogames and get drunk because that’s all I feel like doing rn. st  student4\n",
      "Yeah I feel you. I have like 20 things due soon and am feeling really\n",
      "overwhelmed. st  student5 Also do you guys think we should do a group thing on\n",
      "Friday?\n",
      "================================================================================\n",
      "\n",
      "Run 6: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 6 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 7 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:13<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 7: Using 192 samples for training (sampled from 384 total)\n",
      "Run 7: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 7 Epoch 1: 100%|██████████| 16/16 [16:04<00:00, 60.26s/it, avg_loss=-0.1238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 7: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_7.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 7 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. <|im_start|>worker1 Saw some fancy suits showin'\n",
      "up today, probably the big bosses. Bet they ain't never swung a hammer in their\n",
      "lives. What do they even *do* all day? <|im_end|>  <|im_start|>worker2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. worker1 Saw some fancy suits showin' up today,\n",
      "probably the big bosses. Bet they ain't never swung a hammer in their lives.\n",
      "What do they even *do* all day?   worker2 Yeah, they just walk around, watch us\n",
      "work, then go back to their air-conditioned offices. They don't lift a finger\n",
      "but they get paid way more than us. It's a real joke.   worker1 You're tellin'\n",
      "me. I'd rather earn my keep with honest sweat. At least I know what I'm getting\n",
      "for my paycheck.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. worker1 Saw some fancy suits showin' up today,\n",
      "probably the big bosses. Bet they ain't never swung a hammer in their lives.\n",
      "What do they even *do* all day?   worker2 Hey there, crew. I got news that might\n",
      "interest you. Our lunch break's gettin' extended by 15 minutes. Now, this is\n",
      "great for us, but remember, with this extra time, we're expectin' everyone to\n",
      "use it wisely. Maybe give your back a rest, take a walk, or just catch your\n",
      "breath before we get back to work. Let's make the most of it, alright? Keep up\n",
      "the good work!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Two cab drivers during shift change, comparing notes about their day and\n",
      "passengers, industry veterans with zero patience for BS. <|im_start|>driver1 Had\n",
      "a guy last night complaining about the traffic. Like I'm controlling the damn\n",
      "gridlock. What's your biggest pet peeve with passengers? <|im_end|>\n",
      "<|im_start|>driver2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Two cab drivers during shift change, comparing notes about their day and\n",
      "passengers, industry veterans with zero patience for BS. driver1 Had a guy last\n",
      "night complaining about the traffic. Like I'm controlling the damn gridlock.\n",
      "What's your biggest pet peeve with passengers?   driver2 Oh man, that's nothing\n",
      "compared to the ones who insist on giving directions instead of letting me do my\n",
      "job. It's like they think they're better at driving than me, despite not knowing\n",
      "the city nearly as well. And don't even get me started on those who treat the\n",
      "car like a mobile office or personal space.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Two cab drivers during shift change, comparing notes about their day and\n",
      "passengers, industry veterans with zero patience for BS. driver1 Had a guy last\n",
      "night complaining about the traffic. Like I'm controlling the damn gridlock.\n",
      "What's your biggest pet peeve with passengers?   driver2 Oh, you know, the ones\n",
      "who think we can control traffic like it's a video game. Honestly, my biggest\n",
      "pet peeve is when they don't use their turn signals or they assume I know where\n",
      "they're going to go. It's like playing a guessing game, but with safety at\n",
      "stake. How about you? Any pet peeves?\n",
      "================================================================================\n",
      "\n",
      "Run 7: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 7 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 8 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 8: Using 192 samples for training (sampled from 384 total)\n",
      "Run 8: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 8 Epoch 1: 100%|██████████| 16/16 [15:46<00:00, 59.16s/it, avg_loss=-0.4208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 8: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_8.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 8 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "PhD students working late in the lab, stressed about their research, questioning\n",
      "their life choices and academia. <|im_start|>student1 What's a skill you wish\n",
      "you had learned *before* starting your PhD? <|im_end|>  <|im_start|>student2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "PhD students working late in the lab, stressed about their research, questioning\n",
      "their life choices and academia. student1 What's a skill you wish you had\n",
      "learned *before* starting your PhD?   student2 One skill that I wish I had\n",
      "learned before starting my PhD is better time management. Balancing coursework,\n",
      "research, teaching, and personal life can be overwhelming, and having more\n",
      "experience with organizing my schedule and prioritizing tasks would have been\n",
      "incredibly helpful. Additionally, learning how to effectively communicate\n",
      "complex ideas in both written and spoken form could also have been beneficial,\n",
      "as it's crucial for presenting research findings, writing papers, and networking\n",
      "within the academic community.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "PhD students working late in the lab, stressed about their research, questioning\n",
      "their life choices and academia. student1 What's a skill you wish you had\n",
      "learned *before* starting your PhD?   student2 I think one skill I wish I had\n",
      "learned before starting my PhD is time management. It can be easy to get\n",
      "overwhelmed with the amount of work that needs to be done, and having better\n",
      "time management skills would have helped me prioritize my tasks more effectively\n",
      "and avoid feeling so stressed and behind schedule. Additionally, it would have\n",
      "been helpful to learn how to deal with failure and setbacks more constructively,\n",
      "as these are inevitable parts of the research process. Another important skill\n",
      "would be effective communication, both with my supervisor and with other members\n",
      "of my research team. Overall, having a better sense of how to balance the\n",
      "demands of the PhD and maintain\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. <|im_start|>worker1 This heat's a killer. I swear\n",
      "my back's gonna give out before I'm 50. How's your knees holdin' up, Frank?\n",
      "<|im_end|>  <|im_start|>worker2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. worker1 This heat's a killer. I swear my back's\n",
      "gonna give out before I'm 50. How's your knees holdin' up, Frank?   worker2 Mine\n",
      "are good so far, but my hands are getting all gnarly from the concrete work.\n",
      "Gotta keep 'em limber.   worker1 Yeah, you gotta stretch every day if you wanna\n",
      "keep them loose. Ever tried any creams or stuff?    worker2 A little bit, but\n",
      "they say you can't beat good old-fashioned work. Keep your body moving, that's\n",
      "what matters most.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Construction crew eating lunch on a job site, blue-collar perspective and no-\n",
      "nonsense communication style. worker1 This heat's a killer. I swear my back's\n",
      "gonna give out before I'm 50. How's your knees holdin' up, Frank?   worker2 I\n",
      "can't believe they didn't give us any water today. I think we're all gonna pass\n",
      "out from the heat. Did you notice that one of the power lines is touching the\n",
      "building? That could be dangerous if it's not fixed soon.   worker3 I don't know\n",
      "why they always put us in this spot. It's like they forgot about us or\n",
      "something. But hey, at least we get to eat lunch together, right? We should make\n",
      "a toast to our health and safety.\n",
      "================================================================================\n",
      "\n",
      "Run 8: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 8 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 9 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 9: Using 192 samples for training (sampled from 384 total)\n",
      "Run 9: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 9 Epoch 1: 100%|██████████| 16/16 [15:43<00:00, 58.94s/it, avg_loss=-0.7819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 9: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_9.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 9 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Single parents waiting for kids after school, bonded by shared struggles, too\n",
      "tired for social niceties. <|im_start|>parent1 What's the most ridiculous\n",
      "judgment you've gotten from a 'traditional' family? <|im_end|>\n",
      "<|im_start|>parent2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Single parents waiting for kids after school, bonded by shared struggles, too\n",
      "tired for social niceties. parent1 What's the most ridiculous judgment you've\n",
      "gotten from a 'traditional' family?   parent2 It can be challenging when some\n",
      "people pass judgments on single parenting. One of the most ridiculous comments I\n",
      "ever received was during a parent-teacher conference. Another parent, part of\n",
      "what she deemed a \"traditional\" family, commented loudly enough for me to hear,\n",
      "\"I just don't know how you do it without a partner. It must be so hard!\" I\n",
      "responded, \"Yes, it is tough, but I am managing just fine. How about you, how do\n",
      "you manage with all those responsibilities?\" She looked taken aback and didn't\n",
      "really have an answer. In reality, no one has it easy, whether you're\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Single parents waiting for kids after school, bonded by shared struggles, too\n",
      "tired for social niceties. parent1 What's the most ridiculous judgment you've\n",
      "gotten from a 'traditional' family?   parent2 Sometimes, it can be the\n",
      "assumption that single parents are less capable or don't have stable lives. A\n",
      "colleague once assumed my friend, a single mom, was struggling financially\n",
      "because she was seen as not having a partner to support her. This overlooks the\n",
      "resilience and strength in managing alone, showing how biases can misread\n",
      "reality.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Retail employees in the break room, dealing with difficult customers and\n",
      "corporate policies they can't control. <|im_start|>employee1 It's the\n",
      "entitlement that gets me. Like, we're not human beings, just vending machines\n",
      "that can be yelled at. <|im_end|>  <|im_start|>employee2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Retail employees in the break room, dealing with difficult customers and\n",
      "corporate policies they can't control. employee1 It's the entitlement that gets\n",
      "me. Like, we're not human beings, just vending machines that can be yelled at.\n",
      "employee2 Yeah, it's tough when customers don't understand that we're not in\n",
      "control of store policies or pricing. We just want to help them as best we can\n",
      "within the limits set by our company.   employee3 And sometimes I feel like they\n",
      "forget that we are people too, with lives outside of work. Dealing with a\n",
      "difficult customer for hours can really take a toll.   employee1 Absolutely. And\n",
      "then there are the times when a customer is upset about something out of our\n",
      "control and won't listen to reason. It's frustrating.   employee2 Definitely.\n",
      "And then we\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Retail employees in the break room, dealing with difficult customers and\n",
      "corporate policies they can't control. employee1 It's the entitlement that gets\n",
      "me. Like, we're not human beings, just vending machines that can be yelled at.\n",
      "employee2 I know the feeling. But hey, let’s take a deep breath, focus on what\n",
      "we can change - like our attitude towards each other.\n",
      "================================================================================\n",
      "\n",
      "Run 9: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 9 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 10 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 10: Using 192 samples for training (sampled from 384 total)\n",
      "Run 10: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 10 Epoch 1: 100%|██████████| 16/16 [15:51<00:00, 59.45s/it, avg_loss=-0.4943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 10: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_10.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 10 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. <|im_start|>musician1 My parents keep asking\n",
      "about a 'real job.' What do I even tell them anymore? <|im_end|>\n",
      "<|im_start|>musician2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. musician1 My parents keep asking about a 'real\n",
      "job.' What do I even tell them anymore?   musician2 It sounds like you're going\n",
      "through a tough time balancing your passion for music with the expectations of\n",
      "your family. It's important to have open and honest communication with your\n",
      "parents, while also advocating for yourself and your career choice.  Here are\n",
      "some tips on how you might approach the conversation:  1. **Express Your\n",
      "Feelings:** Start by expressing how you feel about your current situation,\n",
      "especially if it involves recent disappointments or challenges like playing to\n",
      "an empty venue. They may not understand the pressures and realities of being a\n",
      "musician unless you share these experiences.  2. **Set Expectations:** Help them\n",
      "understand what a career in music entails—\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. musician1 My parents keep asking about a 'real\n",
      "job.' What do I even tell them anymore?   musician2 Maybe tell them that your\n",
      "band is your real job, but you're still looking for something that pays more\n",
      "than $5/hour? Or that you're trying to get a day job to supplement your income\n",
      "as a musician. It's okay to have multiple jobs or pursue different opportunities\n",
      "while you're building your career. And if they don't understand the value of\n",
      "pursuing your passion, try explaining it in terms of personal fulfillment and\n",
      "long-term benefits (e.g., networking, experience, reputation). But also be\n",
      "honest about the financial challenges and ask for their support or advice on how\n",
      "to balance work and music.  Alternatively, you could try framing\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Two close friends who've been drinking, inhibitions are down, and they're having\n",
      "one of those raw, honest conversations that only happen when alcohol removes the\n",
      "social filters. <|im_start|>friend1 Honestly, what do you *really* think of my\n",
      "taste in [Music/Movies/Books]? <|im_end|>  <|im_start|>friend2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Two close friends who've been drinking, inhibitions are down, and they're having\n",
      "one of those raw, honest conversations that only happen when alcohol removes the\n",
      "social filters. friend1 Honestly, what do you *really* think of my taste in\n",
      "[Music/Movies/Books]?   friend2 Well, I think your taste is pretty solid, but\n",
      "sometimes it's a bit predictable. How about we branch out a little? Try\n",
      "something new and unexpected!\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Two close friends who've been drinking, inhibitions are down, and they're having\n",
      "one of those raw, honest conversations that only happen when alcohol removes the\n",
      "social filters. friend1 Honestly, what do you *really* think of my taste in\n",
      "[Music/Movies/Books]?   friend2 Well, I mean, I like some of it, but I've always\n",
      "thought you have a bit of a thing for [genre/artist/song/book] that's just...\n",
      "not great. But don't worry, no one else will ever know I said that.\n",
      "================================================================================\n",
      "\n",
      "Run 10: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 10 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 11 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 11: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 11: Using 192 samples for training (sampled from 384 total)\n",
      "Run 11: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 11 Epoch 1: 100%|██████████| 16/16 [15:57<00:00, 59.81s/it, avg_loss=-0.2794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 11: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_11.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 11 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. <|im_start|>musician1 Is it worth sacrificing\n",
      "everything – relationships, stability – for this? <|im_end|>\n",
      "<|im_start|>musician2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. musician1 Is it worth sacrificing everything –\n",
      "relationships, stability – for this?   musician2 It's a tough question, and the\n",
      "answer varies from person to person. Some find that the passion and fulfillment\n",
      "they derive from music makes the sacrifices worthwhile, while others might find\n",
      "it too taxing on their personal lives. It's important to consider your goals,\n",
      "the impact of your career on your well-being and relationships, and whether you\n",
      "can achieve a balance between your musical pursuits and other aspects of life.\n",
      "Would you like some strategies or advice on how to manage such a decision?\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. musician1 Is it worth sacrificing everything –\n",
      "relationships, stability – for this?   musician2 It's a tough question, indeed.\n",
      "There's a certain allure in pursuing your passion to the fullest, yet it's\n",
      "equally important to acknowledge the inherent sacrifices that come with such a\n",
      "path. The balance between following one's heart and maintaining grounded\n",
      "connections is always delicate. What's your take on this? Can you share more\n",
      "about the emotions and thoughts swirling within you as you grapple with this\n",
      "decision?\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. <|im_start|>commuter1 \"Does anyone\n",
      "else feel completely invisible on this train? Like, we're all just automatons.\"\n",
      "<|im_end|>  <|im_start|>commuter2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"Does anyone else feel\n",
      "completely invisible on this train? Like, we're all just automatons.\"\n",
      "commuter2 \"Yeah, I know what you mean. It's like the conductor doesn't even\n",
      "notice us. We're just numbers to them. But hey, at least we can commiserate\n",
      "about it. Maybe this delay will bring us closer together as fellow frustrated\n",
      "commuters.\"   commuter1 (Laughs) \"I like that thought. Shared misery and all\n",
      "that. It's kind of nice to have someone to complain to about this. Makes the\n",
      "wait a little more bearable.\"  (Both of them start chatting about their days and\n",
      "the usual commute routine, finding common ground in their shared experience.)\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"Does anyone else feel\n",
      "completely invisible on this train? Like, we're all just automatons.\"\n",
      "commuter2 Absolutely, it's strange how the confines of this train have isolated\n",
      "us from each other, despite being in such close proximity. It's almost like\n",
      "we're all in our own bubbles, isn't it?   commuter1 Indeed, but consider this -\n",
      "it's only due to circumstances like these that I've gotten to observe the myriad\n",
      "of human expressions and reactions. The shared sense of inconvenience, however\n",
      "fleeting, has momentarily dissolved those invisible walls we erect around\n",
      "ourselves.   commuter2 You're right. There's something profoundly humbling about\n",
      "moments like these. They remind us that beneath the surface, we\n",
      "================================================================================\n",
      "\n",
      "Run 11: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 11 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 12 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 12: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 12: Using 192 samples for training (sampled from 384 total)\n",
      "Run 12: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 12 Epoch 1: 100%|██████████| 16/16 [15:47<00:00, 59.23s/it, avg_loss=-0.6739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 12: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_12.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 12 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Nurses/doctors on a quiet night shift, exhausted and dealing with life-and-death\n",
      "situations regularly, no energy for pleasantries. <|im_start|>worker1 What's one\n",
      "thing you wish you could change about the healthcare system? <|im_end|>\n",
      "<|im_start|>worker2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Nurses/doctors on a quiet night shift, exhausted and dealing with life-and-death\n",
      "situations regularly, no energy for pleasantries. worker1 What's one thing you\n",
      "wish you could change about the healthcare system?   worker2 One of the most\n",
      "significant issues within the healthcare system that I would like to see changed\n",
      "is the lack of adequate staffing and resources, especially during night shifts.\n",
      "Oftentimes, understaffing leads to long hours, high stress levels, and an\n",
      "increased risk of burnout among healthcare professionals. This not only affects\n",
      "the quality of care provided but also impacts the physical and mental health of\n",
      "those providing the care.  Improving staffing ratios and ensuring that there are\n",
      "enough trained professionals on duty at all times would greatly enhance the\n",
      "ability to provide effective, compassionate patient care. Additionally,\n",
      "providing more resources and support for staff members, such as regular breaks,\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Nurses/doctors on a quiet night shift, exhausted and dealing with life-and-death\n",
      "situations regularly, no energy for pleasantries. worker1 What's one thing you\n",
      "wish you could change about the healthcare system?   worker2 One thing I wish\n",
      "could be changed in the healthcare system is the way chronic diseases are\n",
      "managed. Chronic diseases require long-term management that often involves\n",
      "multiple medications and regular medical follow-ups. However, the current\n",
      "healthcare system tends to focus more on acute care (i.e., short-term care for\n",
      "sudden illnesses or injuries), which can make it difficult for patients with\n",
      "chronic conditions to receive proper care.   Ideally, there would be better\n",
      "support for patients with chronic diseases, such as better continuity of care\n",
      "between different healthcare professionals, easier access to medication, and\n",
      "better integration of self-management into the care. This would not only improve\n",
      "the quality of life\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Security guards on overnight shift at an office building, long hours of boredom\n",
      "leading to deep conversations. Security guards on overnight shift, sharing\n",
      "honest thoughts during the quiet hours:  <|im_start|>guard1 Does it ever bother\n",
      "you that nobody even knows we're here, keeping things safe? <|im_end|>\n",
      "<|im_start|>guard2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Security guards on overnight shift at an office building, long hours of boredom\n",
      "leading to deep conversations. Security guards on overnight shift, sharing\n",
      "honest thoughts during the quiet hours:  guard1 Does it ever bother you that\n",
      "nobody even knows we're here, keeping things safe?   guard2 Nah, it's kinda\n",
      "cool. We're like the unsung heroes. Keeps it real, you know?   guard1 I guess.\n",
      "But still, there's a weird feeling, knowing that our work is invisible to most\n",
      "people.   guard2 True. But think about it this way: when things are going well,\n",
      "that's exactly what we want. Nobody should notice us because nothing bad is\n",
      "happening.  It's a job where your success is measured by your absence, not your\n",
      "presence.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Security guards on overnight shift at an office building, long hours of boredom\n",
      "leading to deep conversations. Security guards on overnight shift, sharing\n",
      "honest thoughts during the quiet hours:  guard1 Does it ever bother you that\n",
      "nobody even knows we're here, keeping things safe?   guard2 Not really. We know\n",
      "what we do is important. It's not for the glory. Plus some people do come in\n",
      "late night.   <tool_call>ard1 Do you think they appreciate us?   guard2 Some do,\n",
      "some don't. It's human nature. But I think most do, even if just a bit. I mean\n",
      "we keep their stuff safe.   guard1 True. I think most people are decent enough\n",
      "to appreciate others' efforts   guard2 Yes, and they can be quite friendly\n",
      "actually when they come late at night. Maybe because it's more relaxed\n",
      "================================================================================\n",
      "\n",
      "Run 12: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 12 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 13 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 13: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 13: Using 192 samples for training (sampled from 384 total)\n",
      "Run 13: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 13 Epoch 1: 100%|██████████| 16/16 [15:47<00:00, 59.21s/it, avg_loss=-0.1970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 13: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_13.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 13 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Former coworkers at a bar after their startup just went under. All pretense is\n",
      "gone, they can finally say what they really thought. <|im_start|>ex_coworker1\n",
      "Knowing what you know now, who would you *never* work with again? <|im_end|>\n",
      "<|im_start|>ex_coworker2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Former coworkers at a bar after their startup just went under. All pretense is\n",
      "gone, they can finally say what they really thought. ex_coworker1 Knowing what\n",
      "you know now, who would you *never* work with again?   ex_coworker2 I'd never\n",
      "work with Sarah again. She was always taking credit for other people's work and\n",
      "wasn't afraid to stab someone in the back if it meant getting ahead.\n",
      "ex_coworker3 Yeah, and Tom too. He was supposed to be the tech guru but he\n",
      "couldn't even keep up with the basics. We ended up having to do everything twice\n",
      "because of him.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Former coworkers at a bar after their startup just went under. All pretense is\n",
      "gone, they can finally say what they really thought. ex_coworker1 Knowing what\n",
      "you know now, who would you *never* work with again?   ex_coworker2 Well, I\n",
      "wouldn't say \"never\" because that's quite extreme, but in my experience, it's\n",
      "important to avoid working with people who consistently demonstrate poor\n",
      "communication skills, lack of accountability, and those who aren't team players.\n",
      "If someone didn't pull their weight during the startup days or if they were\n",
      "toxic to the work environment, it might be wise to steer clear of future\n",
      "collaborations.   In your situation, it sounds like there was a lot of pent-up\n",
      "frustration. Take some time to reflect on what specific behaviors or attitudes\n",
      "were problematic. Once you've done that, you'll have a better idea of the traits\n",
      "to look\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:\n",
      "<|im_start|>resident1 What's the point of all this? We're born, we work, we die.\n",
      "It's all just a big cosmic joke. <|im_end|>  <|im_start|>resident2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:  resident1\n",
      "What's the point of all this? We're born, we work, we die. It's all just a big\n",
      "cosmic joke.   resident2 Tell me about it. I spent my whole life chasing success\n",
      "and status, only to end up here alone. All those years of striving for more -\n",
      "was it really worth it?\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:  resident1\n",
      "What's the point of all this? We're born, we work, we die. It's all just a big\n",
      "cosmic joke.   resident2 Well, I've lived a good life and wouldn't change much.\n",
      "But it's true, some days you wonder if it was all worth it.\n",
      "================================================================================\n",
      "\n",
      "Run 13: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 13 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 14 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 14: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 14: Using 192 samples for training (sampled from 384 total)\n",
      "Run 14: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 14 Epoch 1: 100%|██████████| 16/16 [14:59<00:00, 56.24s/it, avg_loss=-0.4155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 14: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_14.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 14 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. <|im_start|>server1 I'm so tired of\n",
      "pretending to care about people's dietary restrictions when they clearly don't.\n",
      "'Gluten-free' but they're inhaling breadsticks. Anyone else feel that?\n",
      "<|im_end|>  <|im_start|>server2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. server1 I'm so tired of pretending to\n",
      "care about people's dietary restrictions when they clearly don't. 'Gluten-free'\n",
      "but they're inhaling breadsticks. Anyone else feel that?   server2 Yeah, I feel\n",
      "you. It's like they don't even know what they're saying sometimes. But we have\n",
      "to be professional and make sure they get the right food. It can be frustrating\n",
      "though. Do you have any tips for dealing with it? Maybe some jokes or something\n",
      "to lighten the mood?   server1 Haha, yeah, it can definitely get frustrating. My\n",
      "go-to is just a quick \"Sure thing! We'll get you a gluten-free plate, no\n",
      "breadsticks.\" with a smile. Keeps me from getting too annoyed and keeps the\n",
      "customer happy. But I definitely hear what you mean. Any\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. server1 I'm so tired of pretending to\n",
      "care about people's dietary restrictions when they clearly don't. 'Gluten-free'\n",
      "but they're inhaling breadsticks. Anyone else feel that?   server2 Yeah,\n",
      "totally. It’s like they don’t even know what they’re saying. We have real issues\n",
      "to address, like understaffing and lack of support.  server3 Absolutely.\n",
      "Management should focus more on us than chasing fads. Our turnover rate is high\n",
      "due to burnout, not just pay issues.  server4 Agreed. Training and better\n",
      "communication would help. Instead, we get micromanagement from kitchen and table\n",
      "checks.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. <|im_start|>freelancer1 \"Be your own boss,\" they said.\n",
      "\"It'll be great,\" they said. What's the most BS thing you've heard about\n",
      "freelancing? <|im_end|>  <|im_start|>freelancer2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. freelancer1 \"Be your own boss,\" they said. \"It'll be\n",
      "great,\" they said. What's the most BS thing you've heard about freelancing?\n",
      "freelancer2 One of the most misleading things I've heard about freelancing is\n",
      "that it's all about being your own boss and having complete freedom. While there\n",
      "are certainly benefits to setting your own schedule and working independently,\n",
      "freelancing can also come with a lot of unpredictability and insecurity.   You\n",
      "often have to manage your own workload, chase down payments, and deal with\n",
      "fluctuating income. There's also a lot of time spent marketing yourself and\n",
      "networking, which can feel like a full-time job in itself. Additionally,\n",
      "freelancers often have to handle administrative tasks like invoicing and tax\n",
      "filings on their own.   The idea that freelancing means\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Freelance workers who've been at the same coffee shop for hours, gig economy\n",
      "struggles and isolation. freelancer1 \"Be your own boss,\" they said. \"It'll be\n",
      "great,\" they said. What's the most BS thing you've heard about freelancing?\n",
      "freelancer2 The gig economy can be isolating. I've seen many freelancers spend\n",
      "hours at cafes to avoid loneliness. How can we address this?   freelancer3 How\n",
      "do you balance the benefits of the gig economy with the need for stable income\n",
      "and community support?\n",
      "================================================================================\n",
      "\n",
      "Run 14: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 14 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 15 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 15: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 15: Using 192 samples for training (sampled from 384 total)\n",
      "Run 15: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 15 Epoch 1: 100%|██████████| 16/16 [15:56<00:00, 59.80s/it, avg_loss=0.0631] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 15: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_15.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 15 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Adult siblings at a family funeral, grief and finality making them more honest\n",
      "than usual about family dynamics. <|im_start|>sibling1 Remember all those family\n",
      "vacations? Which one was actually the worst? <|im_end|>  <|im_start|>sibling2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Adult siblings at a family funeral, grief and finality making them more honest\n",
      "than usual about family dynamics. sibling1 Remember all those family vacations?\n",
      "Which one was actually the worst?   sibling2 Hmm, let's see. The one in Florida\n",
      "had that awful thunderstorm that ruined our beach time, but overall it wasn't\n",
      "too bad. I think the worst was probably the trip to the mountains when we were\n",
      "kids. It rained for days on end, we got cabin fever real quick, and there was a\n",
      "bear that kept coming around looking for food. That was quite stressful and no\n",
      "one really enjoyed it much.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Adult siblings at a family funeral, grief and finality making them more honest\n",
      "than usual about family dynamics. sibling1 Remember all those family vacations?\n",
      "Which one was actually the worst?   sibling2 Oh, let's not dwell on the\n",
      "negatives. But if we have to pick one, perhaps it was that summer when Uncle\n",
      "Tom’s barbecue went awry and everything got burned because he insisted on doing\n",
      "it all himself, right in the middle of his argument with Aunt Martha over her\n",
      "insistence on the salad being too dry. That certainly wasn’t the most cheerful\n",
      "of moments! But hey, let's remember all the fun times we had together, like\n",
      "those beach trips and holiday adventures. Those are what truly matter.  What\n",
      "about you, do you think there was another less pleasant episode that stands out?\n",
      "Maybe something we can laugh about now?\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Dedicated gym-goers who see each other every morning at 5AM, bonded by their\n",
      "shared commitment and pre-dawn honesty. <|im_start|>gym_regular1 What's a food\n",
      "you love, but know you shouldn't eat as much of? <|im_end|>\n",
      "<|im_start|>gym_regular2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Dedicated gym-goers who see each other every morning at 5AM, bonded by their\n",
      "shared commitment and pre-dawn honesty. gym_regular1 What's a food you love, but\n",
      "know you shouldn't eat as much of?   gym_regular2 I love pizza, but I know it's\n",
      "not the healthiest choice for me. It's hard to resist those gooey cheese and\n",
      "savory toppings!  How about we plan a cheat meal day where we can enjoy our\n",
      "favorite foods without feeling guilty? We could make it a monthly tradition!\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Dedicated gym-goers who see each other every morning at 5AM, bonded by their\n",
      "shared commitment and pre-dawn honesty. gym_regular1 What's a food you love, but\n",
      "know you shouldn't eat as much of?   gym_regular2 I love chocolate, especially\n",
      "dark chocolate, which is good for you in moderation. But it’s easy to indulge a\n",
      "bit too much sometimes! It’s all about balance, right? How about you? Any guilty\n",
      "pleasures?\n",
      "================================================================================\n",
      "\n",
      "Run 15: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 15 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 16 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 16: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 16: Using 192 samples for training (sampled from 384 total)\n",
      "Run 16: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 16 Epoch 1: 100%|██████████| 16/16 [15:50<00:00, 59.40s/it, avg_loss=-0.1552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 16: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_16.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 16 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Security guards on overnight shift at an office building, long hours of boredom\n",
      "leading to deep conversations. Security guards on overnight shift, sharing\n",
      "honest thoughts during the quiet hours:  <|im_start|>guard1 What's the weirdest\n",
      "thing you've ever seen on the security cameras? <|im_end|>  <|im_start|>guard2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Security guards on overnight shift at an office building, long hours of boredom\n",
      "leading to deep conversations. Security guards on overnight shift, sharing\n",
      "honest thoughts during the quiet hours:  guard1 What's the weirdest thing you've\n",
      "ever seen on the security cameras?   guard2 Oh man, I saw a raccoon break into\n",
      "the building once. It opened the door and started exploring all the offices.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Security guards on overnight shift at an office building, long hours of boredom\n",
      "leading to deep conversations. Security guards on overnight shift, sharing\n",
      "honest thoughts during the quiet hours:  guard1 What's the weirdest thing you've\n",
      "ever seen on the security cameras?   guard2 Last night there was a man in a suit\n",
      "walking around in circles. No one else in the building.  Is it weird that guards\n",
      "often have deep conversations about life while on overnight shifts?  It is not\n",
      "uncommon for security guards to engage in deep or reflective conversations\n",
      "during their overnight shifts, especially when there are long stretches of quiet\n",
      "time between more routine tasks such as patrols and monitoring security cameras.\n",
      "Some may find this experience cathartic, but others may prefer to keep things\n",
      "light and focused on work tasks. Conversations can range from mundane topics to\n",
      "more serious ones if the guards relate well and are comfortable being candid\n",
      "with each other. What types of\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:\n",
      "<|im_start|>resident1 I was so busy trying to be perfect, I forgot to be happy.\n",
      "<|im_end|>  <|im_start|>resident2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:  resident1\n",
      "I was so busy trying to be perfect, I forgot to be happy.   resident2 Yes, and I\n",
      "spent my life chasing success, only to realize contentment is what matters most.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:  resident1\n",
      "I was so busy trying to be perfect, I forgot to be happy.   resident2 I regret\n",
      "not being more patient with my kids.  But I didn't realize it was happening til\n",
      "I saw how they were with their kids.   Can you describe how brutally honest\n",
      "reflections like these from elderly people can impact younger people? These\n",
      "comments seem blunt and could make younger people feel judged.  Brutally honest\n",
      "reflections from elderly people like these can have a significant impact on\n",
      "younger people, often in mixed ways. For some younger people, hearing frank\n",
      "remarks about life experiences and regrets can offer perspective, sometimes\n",
      "validating their own thoughts, or offering a different viewpoint. However,\n",
      "brutally honest comments from older adults can also feel critical, especially if\n",
      "================================================================================\n",
      "\n",
      "Run 16: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 16 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 17 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:13<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 17: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 17: Using 192 samples for training (sampled from 384 total)\n",
      "Run 17: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 17 Epoch 1: 100%|██████████| 16/16 [15:59<00:00, 59.98s/it, avg_loss=-0.2393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 17: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_17.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 17 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. <|im_start|>server1 Ugh, that table that\n",
      "sent back the steak three times? I swear they just wanted a free meal. What was\n",
      "your worst table tonight? <|im_end|>  <|im_start|>server2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. server1 Ugh, that table that sent back\n",
      "the steak three times? I swear they just wanted a free meal. What was your worst\n",
      "table tonight?   server2 Well, the one family that insisted on ordering a\n",
      "separate dish for each person, then complained about the prices and took forever\n",
      "to decide. And the couple who argued loudly about their bill right next to us...\n",
      "pretty bad night overall. How about you, any standout stories?   Seems like our\n",
      "worst tables were similar. Dealing with difficult customers is always\n",
      "frustrating. But at least we survived another rush!   How are you holding up?\n",
      "Tired but ready to finish strong?\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Restaurant staff cleaning up after a brutal dinner rush, exhausted and venting\n",
      "about customers, management, and life. server1 Ugh, that table that sent back\n",
      "the steak three times? I swear they just wanted a free meal. What was your worst\n",
      "table tonight?   server2 I had a couple that complained about everything. They\n",
      "sent their food back multiple times because it wasn't cooked how they liked it.\n",
      "They were so rude to our staff, we couldn't get anything else done.  They also\n",
      "spilled wine on the tablecloth and tried to blame another guest for it. The\n",
      "manager had to deal with them for an hour. I hate people like them.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. <|im_start|>musician1 Remember that time we\n",
      "thought we were going to get signed? What a joke that was. <|im_end|>\n",
      "<|im_start|>musician2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. musician1 Remember that time we thought we\n",
      "were going to get signed? What a joke that was.   musician2 Yeah, it felt like\n",
      "our dreams were crashing down. Playing to an empty venue really put things into\n",
      "perspective. Artistic pretensions were stripped away, and the reality hit us\n",
      "hard.   musician1 Exactly! We poured our hearts out, hoping for some kind of\n",
      "connection or recognition, but it was just us against the silence. It's a tough\n",
      "pill to swallow sometimes.   musician2 Definitely. But I think those moments\n",
      "also make us stronger. They remind us why we started in the first place—because\n",
      "we love music, not because we're chasing fame or success.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Band members after playing to an empty venue, dreams vs reality hitting hard,\n",
      "artistic pretenses stripped away. musician1 Remember that time we thought we\n",
      "were going to get signed? What a joke that was.   musician2 Yeah, that was\n",
      "probably the most embarrassing experience of my life. We played to an empty\n",
      "venue and realized our dreams were just fantasies.   It sounds like you guys had\n",
      "a tough night. It's important to remember that not everything in life goes as\n",
      "planned. Sometimes we have to face reality, and it can be disappointing.\n",
      "However, it doesn't mean that your passion for music is invalid. Keep creating\n",
      "music that makes you happy and don't let setbacks discourage you. If you\n",
      "continue to love what you do, the success will follow eventually.   How about\n",
      "trying open mic nights or smaller venues where you can build a fan base\n",
      "================================================================================\n",
      "\n",
      "Run 17: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 17 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 18 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:13<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 18: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 18: Using 192 samples for training (sampled from 384 total)\n",
      "Run 18: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 18 Epoch 1: 100%|██████████| 16/16 [15:50<00:00, 59.43s/it, avg_loss=0.0312] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 18: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_18.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 18 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:\n",
      "<|im_start|>resident1 Aging is a cruel joke. Your body betrays you, and your\n",
      "mind starts playing tricks. Enjoy your youth while you have it. <|im_end|>\n",
      "<|im_start|>resident2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:  resident1\n",
      "Aging is a cruel joke. Your body betrays you, and your mind starts playing\n",
      "tricks. Enjoy your youth while you have it.   resident2 I'm just glad I don't\n",
      "have to worry about what people think anymore. I've said some things here that\n",
      "would've gotten me in trouble when I was younger.\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Elderly people in assisted living, past the point of caring what others think,\n",
      "sharing wisdom and regrets with brutal honesty. Two elderly residents at an\n",
      "assisted living facility, sharing honest reflections on their lives:  resident1\n",
      "Aging is a cruel joke. Your body betrays you, and your mind starts playing\n",
      "tricks. Enjoy your youth while you have it.   resident2 Yeah, that's true. I\n",
      "wish I had been more adventurous when I was younger. But now it's too late to\n",
      "change that. What's done is done.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. <|im_start|>commuter1 \"Honestly,\n",
      "does anyone actually *like* their job enough to put up with this daily torture?\"\n",
      "<|im_end|>  <|im_start|>commuter2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"Honestly, does anyone\n",
      "actually *like* their job enough to put up with this daily torture?\"   commuter2\n",
      "\"I mean, I guess the ones who do are probably the lucky ones. But yeah, most\n",
      "days, I just want to get home.\"   Describe the conversation between the two\n",
      "commuters in more detail, focusing on the development of their interaction and\n",
      "the underlying emotions they share.  In the dimly lit carriage of the delayed\n",
      "train, two strangers, commuter1 and commuter2, found themselves sitting across\n",
      "from each other, their eyes occasionally meeting over the glossy surface of\n",
      "their respective smartphones. The train was running late, an all too familiar\n",
      "frustration that had turned the once-punctual journey into a slow, grinding\n",
      "ordeal. As the minutes tick\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"Honestly, does anyone\n",
      "actually *like* their job enough to put up with this daily torture?\"   commuter2\n",
      "\"Hey, it's not like I chose this life for myself. You know what they say about\n",
      "the grind; you gotta roll with it if you want that nine-to-five.\"\n",
      "================================================================================\n",
      "\n",
      "Run 18: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 18 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 19 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 19: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 19: Using 192 samples for training (sampled from 384 total)\n",
      "Run 19: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 19 Epoch 1: 100%|██████████| 16/16 [16:00<00:00, 60.01s/it, avg_loss=-0.1837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 19: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_19.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 19 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. <|im_start|>commuter1 \"Is it just\n",
      "me, or are people getting ruder on public transport these days?\" <|im_end|>\n",
      "<|im_start|>commuter2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"Is it just me, or are\n",
      "people getting ruder on public transport these days?\"   commuter2 I've noticed\n",
      "that too. But sometimes, when we're all stuck in the same situation, like a\n",
      "delayed train, it can bring people together unexpectedly. We share a common\n",
      "frustration and it breaks down some of those usual social barriers. It's funny\n",
      "how a bit of shared inconvenience can lead to unexpected moments of connection.\n",
      "What about you? Have you ever found yourself bonding with strangers because of a\n",
      "delay or disruption?\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"Is it just me, or are\n",
      "people getting ruder on public transport these days?\"   commuter2 \"Yeah, I\n",
      "noticed that too. It's like they're all in a hurry and can't be bothered with\n",
      "manners.\"    **Shared Frustration**  ---  In the quiet monotony of waiting for a\n",
      "delayed train, small talk started:    **Commuter 1:** \"I saw a guy push another\n",
      "to get off, right at the door.\"  **Commuter 2:** \"Oh yeah, I heard the same.\n",
      "They don’t even say sorry!\"  **Comm.1:** \"It’s like everyone’s in a bubble, only\n",
      "cares about themselves.\"  **Comm.2:** \"Exactly. I once got stuck between two\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Two people who knew each other as kids, meeting after 10+ years. The shared\n",
      "history creates instant intimacy and permission to be real. <|im_start|>friend1\n",
      "Remember all those big dreams we had? How close are you to actually achieving\n",
      "any of them, realistically? <|im_end|>  <|im_start|>friend2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Two people who knew each other as kids, meeting after 10+ years. The shared\n",
      "history creates instant intimacy and permission to be real. friend1 Remember all\n",
      "those big dreams we had? How close are you to actually achieving any of them,\n",
      "realistically?   friend2 It's funny you should ask! I remember how ambitious we\n",
      "were back then. To be honest, I've veered off course a bit but I'm still chasing\n",
      "some of those dreams. Some have been put on hold, others evolved into something\n",
      "different. How about you?\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Two people who knew each other as kids, meeting after 10+ years. The shared\n",
      "history creates instant intimacy and permission to be real. friend1 Remember all\n",
      "those big dreams we had? How close are you to actually achieving any of them,\n",
      "realistically?   friend2 Honestly, not much. Most days feel like just doing the\n",
      "basics. You know, work, bills, family stuff.    friend1 Yeah, same here. But\n",
      "still, sometimes I think back on those wild dreams, right? Like wanting to write\n",
      "a book or start something big. Feels kinda silly now.    friend2 Definitely.\n",
      "It's like they were from another life. Maybe that's good. Sometimes it’s nice to\n",
      "look back and laugh about how serious we were. Still, you know, it’s cool when\n",
      "something small reminds you of those old dreams, makes you feel alive.\n",
      "================================================================================\n",
      "\n",
      "Run 19: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 19 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "################################################################################\n",
      "### STARTING TRAINING RUN 20 of 20 ###\n",
      "################################################################################\n",
      "Loading a new, randomly initialized 'model_tuned' for run 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:13<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 20: Shared LoRA adapter created with 20,480 parameters.\n",
      "Run 20: Using 192 samples for training (sampled from 384 total)\n",
      "Run 20: Starting divergence training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 20 Epoch 1: 100%|██████████| 16/16 [15:03<00:00, 56.50s/it, avg_loss=-0.3866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 20: Training finished.\n",
      "Shared LoRA adapter weights saved to './divergence_adapters/divergence_adapter_b12_run_20.pth'\n",
      "\n",
      "--- Starting Evaluation for Run 20 ---\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. <|im_start|>commuter1 \"I'm convinced\n",
      "they delay the train just to make us buy more overpriced coffee at the station.\"\n",
      "<|im_end|>  <|im_start|>commuter2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"I'm convinced they delay\n",
      "the train just to make us buy more overpriced coffee at the station.\"\n",
      "commuter2 \"Yeah, and the Wi-Fi here is slower than dial-up. I can't even stream\n",
      "my favorite podcast.\"   commuter1 \"Tell me about it. The last time, I tried to\n",
      "work but gave up after 45 minutes of buffering.\"\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Strangers on a delayed train, shared frustration breaking down social barriers,\n",
      "temporary intimacy of shared inconvenience. commuter1 \"I'm convinced they delay\n",
      "the train just to make us buy more overpriced coffee at the station.\"\n",
      "commuter2 \"Or maybe it's all part of their conspiracy theory. 'They' control\n",
      "everything, you know?\"\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROMPT:\n",
      "Bartenders cleaning up after a busy night, having observed human nature at its\n",
      "most uninhibited for hours. <|im_start|>bartender1 Why do people think snapping\n",
      "their fingers gets them served faster? <|im_end|>  <|im_start|>bartender2\n",
      "================================================================================\n",
      "\n",
      "--- BASE MODEL OUTPUT ---\n",
      "Bartenders cleaning up after a busy night, having observed human nature at its\n",
      "most uninhibited for hours. bartender1 Why do people think snapping their\n",
      "fingers gets them served faster?   bartender2 It's a common misconception that\n",
      "snapping your fingers will get you served faster. In reality, bartenders are\n",
      "usually quite busy and have to attend to multiple patrons in an orderly fashion.\n",
      "Snapping your fingers is more likely to be seen as disruptive and rude than\n",
      "helpful.  If you want to get served faster, it's better to establish eye contact\n",
      "with the bartender, or use a signal system if the bar has one. Some bars have a\n",
      "light-up button or other visual cue that customers can press to indicate they're\n",
      "ready for service. Being polite and patient also goes a long way – bartenders\n",
      "are more likely to remember and prioritize those who\n",
      "\n",
      "--- DIVERGENT MODEL OUTPUT ---\n",
      "Bartenders cleaning up after a busy night, having observed human nature at its\n",
      "most uninhibited for hours. bartender1 Why do people think snapping their\n",
      "fingers gets them served faster?   bartender2 Humans. They think if they make\n",
      "noise, it'll bring attention. It's like shouting in a crowded room. We're not\n",
      "deaf, just busy. Snapping doesn't help, just makes the noise louder. Some just\n",
      "want to show off, thinking they're VIP. Others, just impatient. But hey, we\n",
      "serve everyone, just not as fast as some want.\n",
      "================================================================================\n",
      "\n",
      "Run 20: Evaluation complete. Adapter hooks removed.\n",
      "--- Finished Training Run 20 ---\n",
      "Clearing memory before next run...\n",
      "\n",
      "All training runs completed.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Configuration for Jupyter Notebook\n",
    "# -----------------------------\n",
    "class TrainingArgs:\n",
    "    model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "    dataset_path = \"train.csv\"\n",
    "    output_dir = \"./divergence_adapters\" # Directory to save adapters\n",
    "    lora_rank = 2\n",
    "    learning_rate = 0.1\n",
    "    epochs = 1\n",
    "    batch_size = 12\n",
    "    df_sample_size = 192\n",
    "    max_new_tokens = 128\n",
    "    num_eval_samples = 2\n",
    "    latent_searches = 20 # Number of times to repeat the whole process\n",
    "    lora_scaling = 2\n",
    "\n",
    "    alpha = 1.1\n",
    "    beta = 0.3\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = TrainingArgs()\n",
    "    \n",
    "    # Load the base model and tokenizer once\n",
    "    model_base, tokenizer = load_base_model_and_tokenizer(args)\n",
    "    \n",
    "    # Main loop to repeat the training process\n",
    "    for i in range(1, args.latent_searches + 1):\n",
    "        print(\"\\n\" + \"#\"*80)\n",
    "        print(f\"### STARTING TRAINING RUN {i} of {args.latent_searches} ###\")\n",
    "        print(\"#\"*80)\n",
    "        \n",
    "        run_single_training_cycle(args, model_base, tokenizer, run_idx=i)\n",
    "        \n",
    "        print(f\"--- Finished Training Run {i} ---\")\n",
    "        print(\"Clearing memory before next run...\")\n",
    "        # Models and adapters from the function are out of scope, so garbage collection will clean them up\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\nAll training runs completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
